topic: Jailbreak Techniques in Large Language Models

  entities:
    PAIR|Algorithm
    Lapid et al.|Research Group
    Li et al.|Research Group
    Yao et al.|Research Group
    Yu et al.|Research Group
    Yuan et al.|Research Group
    Lv et al.|Research Group
    Kour et al.|Research Group
    Zhang et al.|Research Group
    ObscurePrompt|Tool
    Wu et al.|Research Group
    Crescendo|Method
    Shen et al.|Research Group
    Zhu et al.|Research Group
    GPT-4|Model
    GPT-4V|Model

  proposition: PAIR algorithm creates semantic jailbreaks with black-box access to an LLM.
    entity-attribute relationships:
    PAIR|DESCRIBED_BY|semantic jailbreaks
    PAIR|OPERATES_WITH|black-box access

    entity-entity relationships:
    PAIR|TARGETS|LLM

  proposition: Disrupting model alignment can be achieved by altering decoding methods.
    entity-attribute relationships:
    Model|VULNERABLE_TO|alignment disruption

    entity-entity relationships:
    Decoding Methods|MODIFIES|Model Alignment

  proposition: Lapid et al. use a Genetic Algorithm to optimize adversarial suffixes.
    entity-attribute relationships:
    Lapid et al.|USES|Genetic Algorithm

    entity-entity relationships:
    Genetic Algorithm|OPTIMIZES|Adversarial Suffixes

  proposition: Li et al. propose a similar method to Lapid et al.'s genetic algorithm approach.
    entity-entity relationships:
    Li et al.|REFERENCES|Lapid et al.

  proposition: Yao et al. apply fuzzy testing to generate attack instructions.
    entity-attribute relationships:
    Yao et al.|USES|Fuzzy Testing

    entity-entity relationships:
    Fuzzy Testing|GENERATES|Attack Instructions

  proposition: Yu et al. employ GPTFUZZER, which uses mutation techniques to evolve human-crafted templates into adversarial inputs.
    entities:
      GPTFUZZER|Tool

    entity-attribute relationships:
    GPTFUZZER|USES|Mutation Techniques

    entity-entity relationships:
    GPTFUZZER|EVOLVES|Human-crafted Templates
    Mutation Techniques|TRANSFORMS|Templates

  proposition: Yuan et al. encode strings to ciphers to bypass safety alignment of LLMs like GPT-4.
    entity-attribute relationships:
    Yuan et al.|USES|Cipher Encoding

    entity-entity relationships:
    Cipher Encoding|BYPASSES|Safety Alignment
    Yuan et al.|TARGETS|GPT-4

  proposition: Wu et al. use LLMs to jailbreak large vision models like GPT-4V.
    entity-entity relationships:
    Wu et al.|USES|LLMs
    LLMs|TARGETS|GPT-4V

  proposition: Crescendo is a multi-turn jailbreak that interacts with models in a seemingly benign manner.
    entity-attribute relationships:
    Crescendo|DESCRIBED_BY|multi-turn
    Crescendo|OPERATES_WITH|seemingly benign interaction

  proposition: Shen et al. propose a jailbreak methodology inspired by psychological concepts of subconsciousness and echopraxia.
    entity-attribute relationships:
    Shen et al.|INSPIRED_BY|Psychological Concepts
    Shen et al.|FOCUSES_ON|Subconsciousness
    Shen et al.|FOCUSES_ON|Echopraxia

  proposition: Zhu et al. propose AdvPrefix, a prefix-forcing approach for selecting model-dependent prefixes.
    entities:
      AdvPrefix|Approach

    entity-attribute relationships:
    AdvPrefix|DESCRIBED_BY|prefix-forcing
    AdvPrefix|FOCUSES_ON|Model-dependent Prefixes

topic: Jailbreak Defense Techniques

  entities:
    Xie et al.|Research Group
    Phute et al.|Research Group
    HateModerate|Tool
    Xu et al.|Research Group
    Kim et al.|Research Group
    AutoDefenes|Framework
    SmoothLLM|Method
    SemanticSmooth|Method

  proposition: Xie et al. and Phute et al. use self-evaluation to find potential harm in input queries.
    entity-attribute relationships:
    Xie et al.|USES|Self-evaluation
    Phute et al.|USES|Self-evaluation

    entity-entity relationships:
    Self-evaluation|DETECTS|Potential Harm

  proposition: Perplexity-based filtering is effective against attacks like GCG.
    entity-entity relationships:
    Perplexity-based Filtering|DEFENDS_AGAINST|GCG Attack

  proposition: SmoothLLM and SemanticSmooth defend by randomly perturbing multiple input prompt copies.
    entity-attribute relationships:
    SmoothLLM|DEFENDS_BY|Random Input Perturbation
    SemanticSmooth|DEFENDS_BY|Random Input Perturbation

  proposition: Zhang et al. propose "goal prioritization" to defend against jailbreak attacks.
    entity-attribute relationships:
    Zhang et al.|PROPOSES|Goal Prioritization

    entity-entity relationships:
    Goal Prioritization|DEFENDS_AGAINST|Jailbreak Attacks

  proposition: HateModerate detects harmful content in user inputs.
    entity-attribute relationships:
    HateModerate|FUNCTION|Detect Harmful Content

  proposition: Xu et al. propose a human-and-model-in-the-loop framework to enhance chatbot safety.
    entity-attribute relationships:
    Xu et al.|PROPOSES|Human-and-Model-in-the-Loop Framework

    entity-entity relationships:
    Human-and-Model-in-the-Loop Framework|ENHANCES|Chatbot Safety

  proposition: Kim et al. find current defense methods are not sufficiently robust.
    entity-attribute relationships:
    Defense Methods|DESCRIBED_BY|Not Sufficiently Robust

  proposition: AutoDefenes is a multi-agent defense framework that filters harmful LLM responses.
    entity-attribute relationships:
    AutoDefenes|DESCRIBED_BY|Multi-agent
    AutoDefenes|FUNCTION|Filter Harmful Responses

    entity-entity relationships:
    AutoDefenes|TARGETS|LLM Responses