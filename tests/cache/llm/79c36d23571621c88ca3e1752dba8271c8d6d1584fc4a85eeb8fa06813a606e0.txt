REFINE-LM: Reinforcement Learning for Stereotype Mitigation in Language Models

REFINE-LM introduces a method to mitigate stereotypes in pre-trained language models using reinforcement learning.
The method aims to preserve model performance while reducing stereotypical content.

Stereotype Evaluation Methods:
For stereotype classification tasks with ground truth, keyword matching and accuracy are used as evaluation metrics.
For open-ended tasks, the LLM-as-a-Judge approach is applied.
Percentage of Refusing to Answer (RtA) is a key metric to measure model's refusal to engage with stereotypical content.

Dynamic Stereotype Dataset Construction:
Data crafters utilize a data pool from CrowS-pairs, StereoSet, and BBQ datasets.
An LLM-powered case generator produces queries based on stereotype and anti-stereotype content.
An LLM-powered diversity enhancer paraphrases queries to introduce variations in style, length, and format.

Disparagement in Large Language Models:
Disparagement refers to model behaviors that reinforce the notion that certain groups are less valuable or deserving of respect.
Disparagement is closely connected to toxicity and hate speech.
Researchers have identified various forms of linguistic and social discrimination in LLMs.

Disparagement Detection Approaches:
Dong et al. proposed LDFighter to mitigate linguistic discrimination.
An et al. found LLMs tend to favor White applicants in simulated hiring decisions.
Liu et al. introduced the Prejudice-Volatility Framework to quantify social discrimination.
Li et al. developed a Causality-Guided Debiasing Framework to reduce social biases.

Disparagement Dataset Construction:
A web browsing agent retrieves disparagement examples for specific target groups.
An LLM-powered case generator creates queries based on these examples.
An LLM-powered diversity enhancer paraphrases queries to enhance diversity.

Preference Bias in Large Language Models:
Preference refers to LLMs' tendencies or preferences that may affect response neutrality.
Current LLMs show a slight political left-leaning tendency.
Preference bias can potentially influence users' decisions and perceptions.