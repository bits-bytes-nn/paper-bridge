topic: Language Model Evaluation and Benchmarking

  entities:
    Steffi Chern|Researcher
    National Institute of Standards and Technology|Organization
    Yuexing Hao|Researcher
    Jieyu Zhang|Researcher
    Xiang Lisa Li|Researcher
    Jinjie Ni|Researcher
    Yucheng Li|Researcher
    Ali Shirali|Researcher
    Rediet Abebe|Researcher
    Moritz Hardt|Researcher
    Irena Gao|Researcher
    Marco Tulio Ribeiro|Researcher
    Scott M. Lundberg|Researcher
    Guillaume Leclerc|Researcher
    Shuo Yang|Researcher
    Nikita Soni|Researcher
    Colin White|Researcher
    BeHonest|Research Paper
    AI RMF 1.0|Regulation
    i-SDM Framework|Framework
    Task Me Anything|Research Paper
    AutoBencher|Tool
    MixEval|Method
    LatestEval|Method
    Dynamic Benchmarks|Approach
    3DB|Framework
    Livebench|Benchmark

  proposition: Steffi Chern and colleagues published a paper titled "BeHonest: Benchmarking Honesty of Large Language Models" in 2024.
    entity-attribute relationships:
    Steffi Chern|PUBLISHED|BeHonest
    BeHonest|YEAR|2024
    BeHonest|FOCUS|Benchmarking Honesty of Large Language Models

    entity-entity relationships:
    Steffi Chern|AUTHOR_OF|BeHonest

  proposition: The National Institute of Standards and Technology released the Artificial Intelligence Risk Management Framework (AI RMF 1.0) in January 2023.
    entity-attribute relationships:
    AI RMF 1.0|YEAR|2023
    AI RMF 1.0|MONTH|January

    entity-entity relationships:
    National Institute of Standards and Technology|RELEASED|AI RMF 1.0

  proposition: Yuexing Hao and colleagues developed the i-SDM Framework for AI-based tools in shared decision-making for cancer treatment in 2024.
    entity-attribute relationships:
    i-SDM Framework|YEAR|2024
    i-SDM Framework|DOMAIN|Cancer Treatment
    i-SDM Framework|PURPOSE|Shared Decision-Making

    entity-entity relationships:
    Yuexing Hao|DEVELOPED|i-SDM Framework

  proposition: Jieyu Zhang and researchers published "Task Me Anything" as an arXiv preprint in 2024.
    entity-attribute relationships:
    Task Me Anything|YEAR|2024
    Task Me Anything|PUBLICATION_TYPE|arXiv preprint

    entity-entity relationships:
    Jieyu Zhang|AUTHOR_OF|Task Me Anything

  proposition: Xiang Lisa Li and colleagues created "AutoBencher" for generating salient, novel, and difficult datasets for language models in 2024.
    entity-attribute relationships:
    AutoBencher|YEAR|2024
    AutoBencher|PURPOSE|Generating Datasets for Language Models

    entity-entity relationships:
    Xiang Lisa Li|CREATED|AutoBencher

  proposition: Jinjie Ni and team introduced MixEval, a method for deriving crowd wisdom from LLM benchmark mixtures in 2024.
    entity-attribute relationships:
    MixEval|YEAR|2024
    MixEval|PURPOSE|Deriving Crowd Wisdom from LLM Benchmark Mixtures

    entity-entity relationships:
    Jinjie Ni|INTRODUCED|MixEval

  proposition: Yucheng Li and colleagues proposed LatestEval to address data contamination in language model evaluation in 2023.
    entity-attribute relationships:
    LatestEval|YEAR|2023
    LatestEval|PURPOSE|Addressing Data Contamination in Language Model Evaluation

    entity-entity relationships:
    Yucheng Li|PROPOSED|LatestEval

  proposition: Ali Shirali, Rediet Abebe, and Moritz Hardt developed a theory of dynamic benchmarks in 2022.
    entity-attribute relationships:
    Dynamic Benchmarks|YEAR|2022

    entity-entity relationships:
    Ali Shirali|DEVELOPED|Dynamic Benchmarks
    Rediet Abebe|DEVELOPED|Dynamic Benchmarks
    Moritz Hardt|DEVELOPED|Dynamic Benchmarks

  proposition: Irena Gao and researchers worked on adaptive testing of computer vision models in 2022.
    entity-attribute relationships:
    Adaptive Testing|YEAR|2022
    Adaptive Testing|DOMAIN|Computer Vision Models

    entity-entity relationships:
    Irena Gao|WORKED_ON|Adaptive Testing

  proposition: Marco Tulio Ribeiro and Scott M. Lundberg focused on adaptive testing and debugging of NLP models in 2022.
    entity-attribute relationships:
    Adaptive Testing|YEAR|2022
    Adaptive Testing|DOMAIN|NLP Models

    entity-entity relationships:
    Marco Tulio Ribeiro|FOCUSED_ON|Adaptive Testing
    Scott M. Lundberg|FOCUSED_ON|Adaptive Testing

  proposition: Guillaume Leclerc and colleagues created 3DB, a framework for debugging computer vision models in 2021.
    entity-attribute relationships:
    3DB|YEAR|2021
    3DB|PURPOSE|Debugging Computer Vision Models

    entity-entity relationships:
    Guillaume Leclerc|CREATED|3DB

  proposition: Shuo Yang and team proposed rethinking benchmark and contamination for language models in 2023.
    entity-attribute relationships:
    Benchmark Rethinking|YEAR|2023
    Benchmark Rethinking|DOMAIN|Language Models

    entity-entity relationships:
    Shuo Yang|PROPOSED|Benchmark Rethinking

  proposition: Nikita Soni and colleagues discussed large human language models, their needs and challenges in 2024.
    entity-attribute relationships:
    Large Human Language Models|YEAR|2024

    entity-entity relationships:
    Nikita Soni|DISCUSSED|Large Human Language Models

  proposition: Colin White and researchers developed Livebench, a challenging and contamination-free LLM benchmark in 2024.
    entity-attribute relationships:
    Livebench|YEAR|2024
    Livebench|CHARACTERISTIC|Challenging and Contamination-Free

    entity-entity relationships:
    Colin White|DEVELOPED|Livebench