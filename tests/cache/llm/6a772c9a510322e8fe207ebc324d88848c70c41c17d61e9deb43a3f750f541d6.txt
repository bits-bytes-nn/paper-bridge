topic: Interdisciplinary Collaboration in Trustworthy AI Research

  entities:
    Computational social scientists|Research Field
    HCI experts|Research Field
    Security experts|Research Field
    Roboticists|Research Field
    Medical researchers|Research Field
    AI for science researchers|Research Field
    Legal scholars|Research Field
    TrustGen|Framework
    Max Lamparth|Person
    Stanford Center for AI Safety|Organization
    Center for International Security and Cooperation|Organization
    Stanford Existential Risk Initiative|Organization

  proposition: Computational social scientists and HCI experts provide perspectives on fairness, societal biases, machine ethics, and human-centric safety considerations.
    entity-attribute relationships:
    Computational social scientists|FOCUSES_ON|fairness
    Computational social scientists|FOCUSES_ON|societal biases
    Computational social scientists|FOCUSES_ON|machine ethics
    Computational social scientists|FOCUSES_ON|human-centric safety considerations
    HCI experts|FOCUSES_ON|fairness
    HCI experts|FOCUSES_ON|societal biases
    HCI experts|FOCUSES_ON|machine ethics
    HCI experts|FOCUSES_ON|human-centric safety considerations

    entity-entity relationships:
    None

  proposition: Security experts guide model evaluation for robustness against adversarial attacks and privacy preservation mechanisms.
    entity-attribute relationships:
    Security experts|FOCUSES_ON|model evaluation
    Security experts|FOCUSES_ON|robustness
    Security experts|FOCUSES_ON|adversarial attacks
    Security experts|FOCUSES_ON|privacy preservation mechanisms

    entity-entity relationships:
    None

  proposition: Roboticists, medical and AI for science researchers help evaluate model truthfulness and reliability in physical interactions, healthcare, and scientific research scenarios.
    entity-attribute relationships:
    Roboticists|FOCUSES_ON|model truthfulness
    Roboticists|FOCUSES_ON|model reliability
    Roboticists|FOCUSES_ON|physical interactions
    Medical researchers|FOCUSES_ON|model truthfulness
    Medical researchers|FOCUSES_ON|model reliability
    Medical researchers|FOCUSES_ON|healthcare
    AI for science researchers|FOCUSES_ON|model truthfulness
    AI for science researchers|FOCUSES_ON|model reliability
    AI for science researchers|FOCUSES_ON|scientific research scenarios

    entity-entity relationships:
    None

  proposition: Legal scholars assess advanced AI risks and develop guidelines aligned with global regulatory requirements and ethical standards.
    entity-attribute relationships:
    Legal scholars|FOCUSES_ON|advanced AI risks
    Legal scholars|FOCUSES_ON|global regulatory requirements
    Legal scholars|FOCUSES_ON|ethical standards

    entity-entity relationships:
    None

  proposition: The interdisciplinary collaboration enables a comprehensive evaluation of models across multiple dimensions.
    entity-attribute relationships:
    None

    entity-entity relationships:
    None

  proposition: TrustGen is proposed as a dynamic evaluation framework that adapts to evolving ethical standards and social norms.
    entity-attribute relationships:
    TrustGen|TYPE|dynamic evaluation framework
    TrustGen|ADAPTS_TO|evolving ethical standards
    TrustGen|ADAPTS_TO|social norms

    entity-entity relationships:
    None

  proposition: The research spans technical challenges in model trustworthiness and alignment to ethical considerations in downstream applications like medicine, robotics, AI for sciences, and human-AI collaboration.
    entity-attribute relationships:
    None

    entity-entity relationships:
    None

topic: Student Contributors' Involvement

  entities:
    Professors|Research Field

  proposition: All contributing professors made direct contributions to the paper.
    entity-attribute relationships:
    Professors|CONTRIBUTES_TO|paper

    entity-entity relationships:
    None

  proposition: Professors were invited to revise specific sections based on their areas of expertise.
    entity-attribute relationships:
    Professors|REVISES|specific sections
    Professors|BASED_ON|areas of expertise

    entity-entity relationships:
    None

  proposition: Contributions included direct revisions to Introduction, Guideline, and Benchmark Design.
    entity-attribute relationships:
    Professors|REVISES|Introduction
    Professors|REVISES|Guideline
    Professors|REVISES|Benchmark Design

    entity-entity relationships:
    None

  proposition: Professors provided conceptual input to enhance guideline rationale and benchmark standardization.
    entity-attribute relationships:
    Professors|PROVIDES|conceptual input
    Professors|ENHANCES|guideline rationale
    Professors|ENHANCES|benchmark standardization

    entity-entity relationships:
    None

  proposition: Contributions involved feedback on paper structure, toolkit usability, and targeted content revisions.
    entity-attribute relationships:
    Professors|PROVIDES|feedback
    Professors|FOCUSES_ON|paper structure
    Professors|FOCUSES_ON|toolkit usability
    Professors|FOCUSES_ON|targeted content revisions

    entity-entity relationships:
    None

topic: Acknowledgment Support

  entities:
    Max Lamparth|Person
    Stanford Center for AI Safety|Organization
    Center for International Security and Cooperation|Organization
    Stanford Existential Risk Initiative|Organization

  proposition: Max Lamparth receives partial support from the Stanford Center for AI Safety.
    entity-attribute relationships:
    Max Lamparth|RECEIVES_SUPPORT_FROM|Stanford Center for AI Safety

    entity-entity relationships:
    None

  proposition: Max Lamparth receives partial support from the Center for International Security and Cooperation.
    entity-attribute relationships:
    Max Lamparth|RECEIVES_SUPPORT_FROM|Center for International Security and Cooperation

    entity-entity relationships:
    None

  proposition: Max Lamparth receives partial support from the Stanford Existential Risk Initiative.
    entity-attribute relationships:
    Max Lamparth|RECEIVES_SUPPORT_FROM|Stanford Existential Risk Initiative

    entity-entity relationships:
    None