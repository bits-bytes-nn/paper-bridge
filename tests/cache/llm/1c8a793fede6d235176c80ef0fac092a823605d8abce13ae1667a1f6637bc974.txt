Research Papers on Privacy-Preserving Language Model Techniques
Oluwaseyi Feyisetan, Borja Balle, Thomas Drake, and Tom Diethe published a paper on privacy- and utility-preserving textual analysis.
Satyapriya Krishna, Rahul Gupta, and Christophe Dupuy proposed ADePT: an auto-encoder based differentially private text transformation method.
Yansong Li, Zhixing Tan, and Yang Liu developed a privacy-preserving prompt tuning approach for large language models.
Ashwinee Panda, Tong Wu, Jiachen T. Wang, and Prateek Mittal researched privacy-preserving in-context learning for large language models.
Junyuan Hong and colleagues introduced DP-OPT, a method to make large language models privacy-preserving prompt engineers.
Xiaojin Zhang and team explored the "No Free Lunch" theorem for privacy-preserving LLM inference.
Yiming Wang, Yu Lin, Xiaodong Zeng, and Guannan Zhang developed PrivateLoRA for efficient privacy-preserving language models.
Mishaal Kazmi and colleagues created PANORAMIA, a privacy auditing method for machine learning models without retraining.
Haoran Li and team developed PrivLM-Bench, a multi-level privacy evaluation benchmark for language models.
Qinbin Li and researchers proposed LLM-PBE for assessing data privacy in large language models.
Sonu Gupta and colleagues created and analyzed an international corpus of privacy laws.