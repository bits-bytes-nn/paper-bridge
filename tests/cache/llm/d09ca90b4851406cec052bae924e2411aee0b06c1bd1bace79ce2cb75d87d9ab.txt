topic: Vision-Language Model Hallucination

  entities:
    Object Hallucination|Research Problem
    CHAIR|Metric
    POPE|Metric
    LRV-Instruction|Method
    VIGC|Method
    Woodpecker|Method
    HallusionBench|Benchmark
    AutoHallusion|Method
    DALL-E 3|Model
    GPT-4o|Model
    Claude-3.5-Sonnet|Model

  proposition: Object hallucination is a key form of hallucination in vision-language models.
    entity-attribute relationships:
    Object Hallucination|DESCRIBED_BY|key form of hallucination
    
    entity-entity relationships:
    Object Hallucination|OCCURS_IN|Vision-Language Models

  proposition: Object hallucination involves generating nonexistent objects.
    entity-attribute relationships:
    Object Hallucination|INVOLVES|generating nonexistent objects

  proposition: Object hallucination includes attributing incorrect properties to visible objects.
    entity-attribute relationships:
    Object Hallucination|INVOLVES|attributing incorrect properties to visible objects

  proposition: Object hallucination involves misrepresenting relationships between objects in a scene.
    entity-attribute relationships:
    Object Hallucination|INVOLVES|misrepresenting relationships between objects in a scene

  proposition: CHAIR and POPE are metrics that assess caption relevance and hallucination levels.
    entity-attribute relationships:
    CHAIR|ASSESSES|caption relevance
    CHAIR|ASSESSES|hallucination levels
    POPE|ASSESSES|caption relevance
    POPE|ASSESSES|hallucination levels

  proposition: HallusionBench contains 455 visual-question control pairs.
    entity-attribute relationships:
    HallusionBench|CONTAINS|455 visual-question control pairs

  proposition: HallusionBench includes 346 different figures.
    entity-attribute relationships:
    HallusionBench|INCLUDES|346 different figures

  proposition: HallusionBench covers 1129 questions on diverse topics and formats.
    entity-attribute relationships:
    HallusionBench|COVERS|1129 questions
    HallusionBench|COVERS|diverse topics
    HallusionBench|COVERS|diverse formats

  proposition: GPT-4o achieved 71.14% overall accuracy.
    entity-attribute relationships:
    GPT-4o|ACCURACY|71.14%

  proposition: GPT-4o scored 88.04% on existence questions.
    entity-attribute relationships:
    GPT-4o|PERFORMANCE|88.04% on existence questions

  proposition: Claude-3.5-Sonnet achieved 71.14% overall accuracy.
    entity-attribute relationships:
    Claude-3.5-Sonnet|ACCURACY|71.14%

  proposition: Claude-3.5-Sonnet scored 83.70% on existence questions.
    entity-attribute relationships:
    Claude-3.5-Sonnet|PERFORMANCE|83.70% on existence questions