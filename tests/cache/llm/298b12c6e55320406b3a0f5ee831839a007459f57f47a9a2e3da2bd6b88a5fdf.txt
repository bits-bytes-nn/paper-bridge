Research Papers on AI Safety, Adversarial Attacks, and Vision-Language Models
arXiv is a preprint repository for research papers in computer science and related fields.
The collection includes papers focused on adversarial attacks, model robustness, and safety alignment.
Many papers are from 2024 and explore challenges in vision-language models and AI safety.
The papers cover topics like adversarial examples, model robustness, and cross-modal safety alignment.
Some key researchers include Aleksander Madry, Ian J Goodfellow, and various research groups.
The papers are published across conferences like AAAI, ICLR, and as arXiv preprints.
Research venues include international conferences on machine learning and artificial intelligence.
The papers represent cutting-edge research in AI safety, adversarial attacks, and model resilience.