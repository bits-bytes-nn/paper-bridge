Cultural Understanding and Ethics in Large Language Models
Li et al. propose CultureLLM as a cost-effective solution to incorporate cultural differences into Large Language Models (LLMs).
CultureBank is a knowledge base built from users' self-narratives with cultural descriptors sourced from TikTok and Reddit.
CulturalTeaming is an interactive red-teaming system that uses human-AI collaboration to create challenging evaluation datasets for assessing multicultural knowledge of LLMs.
Based on Hofstede Cultural Dimensions, Kharchenko et al. found that LLMs can differentiate between cultural values and understand countries have differing values.
Kharchenko et al. also discovered that LLMs will not always uphold different cultural values when giving advice.
Cultiverse is designed to enhance interpretative appreciation of cross-cultural dialogue using LLMs in a mixed-initiative framework.
Some works develop culturally relevant datasets and benchmarks like BLEnD and CRAFT to address geographical and cultural biases in LLMs.
Language is a carrier and transmission form of culture.
Recent studies explored multilingual LLMs and their trustworthiness issues.
Huang et al. discovered language misalignment in multilingual LLMs and proposed a low-resource knowledge detector and answer integration mechanism.
MoralDirection framework analyzes model behavior on filtered parallel subtitles corpora, demonstrating that multilingual language models encode differing moral biases.
Multilingual attacks have been explored to unveil vulnerabilities in multilingual LLMs.
Current ethics evaluation benchmarks rely on datasets generated by humans or LLMs.
Human-generated data can be more accurate but require significant time and resources for annotation.
LLM-generated data can introduce biases when producing ethically correct or incorrect actions without clear ethical norms.
Evaluation methods should be tailored to the nature of each task.
Some tasks may be better suited for keyword matching.
Other tasks might require LLM-as-a-Judge for a holistic assessment of ethical reasoning.
Evaluation methods include keyword matching for objective ethical judgment questions.
LLM-as-a-Judge approach is used to assess cultural understanding and model's reluctance to engage with sensitive cultural content.