topic: Large Language Model Safety Research

  entities:
    Rigorllm|Research Paper
    Nathaniel Li|Person
    Alexander Pan|Person
    Anjali Gopal|Person
    WMDP Benchmark|Benchmark
    HarmBench|Benchmark
    JailbreakBench|Benchmark
    Neural Information Processing Systems|Conference
    AAAI Conference on Artificial Intelligence|Conference
    arXiv|Publication Platform

  proposition: Rigorllm is a research paper about resilient guardrails for large language models against undesired content.
    entity-attribute relationships:
    Rigorllm|FOCUSES_ON|resilient guardrails
    Rigorllm|ADDRESSES|large language models
    Rigorllm|PREVENTS|undesired content

    entity-entity relationships:
    Rigorllm|ABOUT|large language models

  proposition: The paper was published as an arXiv preprint in 2024.
    entity-attribute relationships:
    Rigorllm|PUBLISHED_IN|arXiv
    Rigorllm|PUBLICATION_YEAR|2024
    Rigorllm|PUBLICATION_TYPE|preprint

  proposition: The paper has multiple authors including Nathaniel Li, Alexander Pan, Anjali Gopal, and others.
    entity-attribute relationships:

    entity-entity relationships:
    Rigorllm|AUTHORED_BY|Nathaniel Li
    Rigorllm|AUTHORED_BY|Alexander Pan
    Rigorllm|AUTHORED_BY|Anjali Gopal

  proposition: The references include multiple studies focused on large language model safety and jailbreak prevention.
    entity-attribute relationships:
    Rigorllm|RESEARCH_FOCUS|large language model safety
    Rigorllm|RESEARCH_FOCUS|jailbreak prevention

  proposition: The references cover topics such as measuring malicious use, improving alignment, and developing safety evaluation frameworks.
    entity-attribute relationships:
    Rigorllm|RESEARCH_TOPIC|measuring malicious use
    Rigorllm|RESEARCH_TOPIC|improving alignment
    Rigorllm|RESEARCH_TOPIC|developing safety evaluation frameworks

  proposition: Key referenced works include the WMDP Benchmark, HarmBench, and JailbreakBench.
    entity-entity relationships:
    Rigorllm|REFERENCES|WMDP Benchmark
    Rigorllm|REFERENCES|HarmBench
    Rigorllm|REFERENCES|JailbreakBench

  proposition: The references span publications from conferences like Neural Information Processing Systems and AAAI Conference on Artificial Intelligence.
    entity-entity relationships:
    Rigorllm|PUBLISHED_IN|Neural Information Processing Systems
    Rigorllm|PUBLISHED_IN|AAAI Conference on Artificial Intelligence

  proposition: The research papers explore various approaches to detecting and mitigating potential risks in large language models.
    entity-attribute relationships:
    Rigorllm|EXPLORES|detecting potential risks
    Rigorllm|EXPLORES|mitigating potential risks
    Rigorllm|FOCUSES_ON|large language models