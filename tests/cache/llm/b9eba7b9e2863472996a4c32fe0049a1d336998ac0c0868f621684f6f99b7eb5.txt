Research Papers on Large Language Model (LLM) Agents and Multi-Agent Systems
Dipayan Saha et al. published a paper titled "LLM for SoC Security: A Paradigm Shift" in IEEE Access in 2024.
Ross Williams et al. conducted research on "Epidemic Modeling with Generative Agents" in an arXiv preprint in 2023.
Chen Gao et al. developed S3: Social-network Simulation System with Large Language Model-Empowered Agents in an arXiv preprint in 2023.
Shenzhi Wang et al. explored "Avalon's Game of Thoughts: Battle Against Deception Through Recursive Contemplation" in an arXiv preprint in 2023.
Weize Chen et al. published "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors" in the Twelfth International Conference on Learning Representations in 2024.
Zhiyu Yang et al. created MatplotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization in an arXiv preprint in 2024.
Geliang Ouyang et al. developed nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow in an arXiv preprint in 2025.
Yi Gui et al. presented UICopilot: Automating UI Synthesis via Hierarchical Code Generation from Webpage Designs in the Web Conference 2025.
Several papers focused on generative models for autonomous driving, including works by Wenzhao Zheng, Yongjie Fu, Anthony Hu, and Shounak Sural.
Tianjie Ju et al. studied the "Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities" in an arXiv preprint in 2024.
Multiple research papers explored Reinforcement Learning from Human Feedback (RLHF), including works by Josef Dai, Tianyu Yu, and Afra Feyza Aky√ºrek.