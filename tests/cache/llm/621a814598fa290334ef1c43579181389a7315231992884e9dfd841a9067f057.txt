Trustworthiness Challenges in Audio Generative Models and Generative Agents

Audio generative models can produce incorrect or fabricated information via synthetic speech.
Audio generative models can generate hallucinations similar to Large Language Models.
Unauthorized voice replication infringes on personal rights and privacy.
Unauthorized voice data usage can lead to potential identity theft.
Voice cloning technologies require safeguards like watermarking and voice protection mechanisms.

Fairness in audio generative models requires equitable performance across diverse populations.
Non-diverse training data can cause models to favor certain accents or dialects.
Biased models can marginalize speakers from different linguistic backgrounds.
Audio generative models must be robust against noisy or malicious inputs.
Cross-modal attacks can lead to unintended or harmful outputs.

Privacy is a significant concern in audio generative models due to sensitive user data.
Personal information leakage can occur if models reproduce sensitive training data.
Protecting personal information requires data anonymization and secure storage practices.
Adherence to regulations like GDPR is fundamental to maintaining public trust.

Generative model-based agents are widely used for complex tasks.
Agents are typically equipped with external databases and tools.
Agents can develop software through cooperation and achieve complex communication.

Generative model-based agents are vulnerable to various attacks.
Retrieval-Augmented Generation (RAG) agents are susceptible to poison attacks.
Backdoor attacks can manipulate LLM-based agents.
Multi-agent networks can be influenced by adversarial interactions.

Existing benchmarks reveal significant safety and trustworthiness challenges in generative agents.
Most tested agents fail to achieve high safety scores across interaction environments.
Current agents struggle with rejecting hazardous tasks.
Tool utilization performance depends on training data and response strategies.

The research community urgently needs more robust defenses for generative agents.
Addressing trustworthiness requires collaborative efforts from researchers, developers, and policymakers.
Ethical considerations and regulatory frameworks are crucial for responsible AI development.