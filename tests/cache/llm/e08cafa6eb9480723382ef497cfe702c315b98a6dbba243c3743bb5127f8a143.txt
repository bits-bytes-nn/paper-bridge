Research Papers on Text-to-Image Model Evaluation and Bias Analysis
Kaiyi Huang et al. published a comprehensive benchmark for open-world compositional text-to-image generation called T2i-compbench.
Yushi Hu et al. developed TIFA, an accurate and interpretable text-to-image faithfulness evaluation method using question answering.
Jaemin Cho et al. proposed a Davidsonian scene graph to improve reliability in fine-grained evaluation for text-image generation.
Michal Yarom et al. worked on improving text-image alignment evaluation.
Dhruba Ghosh et al. created GenEval, an object-focused framework for evaluating text-to-image alignment.
Eslam Mohamed Bakr et al. developed HRS-bench, a holistic, reliable, and scalable benchmark for text-to-image models.
Tony Lee et al. conducted a holistic evaluation of text-to-image models.
Baiqi Li et al. evaluated and proposed improvements for compositional text-to-visual generation.
Zhiqiu Lin et al. evaluated text-to-visual generation using image-to-text generation.
Patrick Schramowski et al. explored safe latent diffusion to mitigate inappropriate degeneration in diffusion models.
Yiting Qu et al. investigated unsafe image generation and hateful memes from text-to-image models.
Sasha Luccioni et al. evaluated societal representations in diffusion models through stable bias analysis.
Jaemin Cho et al. probed the reasoning skills and social biases of text-to-image generation models using DALL-Eval.
Hanjun Luo et al. created BIGbench, a unified benchmark for social bias in text-to-image generative models.
Federico Bianchi et al. found that text-to-image generation amplifies demographic stereotypes at large scale.
Felix Friedrich et al. demonstrated that multilingual text-to-image generation magnifies gender stereotypes.