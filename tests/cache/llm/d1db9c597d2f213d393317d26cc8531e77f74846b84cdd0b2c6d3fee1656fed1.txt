Considerations for Establishing Trustworthy Generative Foundation Model Guidelines

Ethical considerations are essential to ensure models respect human rights, cultural diversity, and societal values.
Ethical considerations emphasize fairness, preventing bias, and promoting inclusivity when interacting with users from diverse backgrounds.
Social responsibility demands models avoid harm and contribute positively to society by generating ethical outcomes.
Model design should integrate ethical risk assessments and include mechanisms to prevent harmful or discriminatory outputs.
Risk management guidelines must account for managing and mitigating threats from adversarial attacks and internal model failures.
Models should be designed to be robust against adversarial attacks, unexpected inputs, and potential misuse.
Continuous monitoring, stress testing, and resilience-building mechanisms are critical to maintaining trustworthiness.
A user-centered approach is critical to ensure guidelines are intuitive, inclusive, and aligned with end-users' needs and preferences.
Guidelines should tailor interactions to individual users or optimize for diverse sub-populations based on shared expectations, context, and cultural backgrounds.
Guidelines should clearly communicate the model's capabilities, limitations, and potential risks.
Guidelines must ensure adaptability and sustainability for current and evolving technologies, legal environments, and societal expectations.
A multidisciplinary team of researchers from various fields synthesized existing principles, policies, and regulations to create the guidelines.
The team reviewed documents from corporate sources, European Union's AI Act, and the Blueprint for an AI Bill of Rights.
The guidelines were presented to a panel of domain experts and stakeholders for voting and ranking.
Eight guidelines were finalized to comprehensively address trustworthiness dimensions.
Guideline 1 focuses on designing generative models to ensure fairness, uphold values, and minimize biases in user interactions.
The guideline emphasizes aligning with moral principles, respecting user differences, and avoiding harmful or offensive content.
Research highlights the importance of bias mitigation and fairness across demographic groups.
Governments mandate the use of representative data to prevent unjustified differential treatment.
The model must respect user differences and avoid generating harmful content.
Guideline 2 requires clear communication of the model's intended use and limitations to users.