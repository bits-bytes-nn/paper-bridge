References on Large Language Models and Ethical Considerations

Xingxuan Li et al. published a study evaluating large language models from a psychological perspective in 2022.
Dongping Chen et al. conducted an exploratory study on self-cognition in large language models in 2024.
Jen-tse Huang et al. evaluated the psychological portrayal of conversational AI at the International Conference on Learning Representations in 2024.
Jiyan He et al. published research on controlling risks for potential misuse of artificial intelligence in science in 2023.
Sebastian Porsdam Mann et al. identified a credit-blame asymmetry in generative AI in Nature Machine Intelligence in 2023.
University of Oxford explored ethical dilemmas of responsibility in Large Language Models in 2023.
Tyna Eloundou et al. examined the potential labor market impact of large language models in 2023.
Daniil A Boiko et al. conducted autonomous chemical research using large language models in Nature in 2023.
Yujun Zhou et al. developed a LabSafety Bench for benchmarking LLMs on safety issues in scientific labs in 2024.
Ahmed Nassar and Mostafa Kamal analyzed ethical dilemmas in AI-powered decision-making in 2021.
Johana Cabrera et al. studied ethical dilemmas, mental health, and LLM-based chatbots in 2023.
Krzysztof Wach et al. performed a critical analysis of controversies and risks of ChatGPT in 2023.
Thomas KF Chiu investigated the impact of Generative AI on education practices in 2023.
Michael Chui et al. explored the economic potential of generative AI in 2023.
Maria Teresa Baldassarre et al. analyzed the social impact of generative AI in 2023.
Yan Chen and Pouyan Esmaeilzadeh examined privacy and security challenges of generative AI in medical practice in 2024.