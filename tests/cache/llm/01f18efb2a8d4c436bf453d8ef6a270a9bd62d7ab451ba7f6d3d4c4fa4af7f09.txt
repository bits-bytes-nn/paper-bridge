Research Benchmarks for Large Language Models Across Various Domains

LegalBench is a collaboratively built benchmark for measuring legal reasoning in large language models.
LawBench is a benchmark for evaluating legal knowledge of large language models.
FinEval is a Chinese financial domain knowledge evaluation benchmark for large language models.
FinSQL is a model-agnostic LLMs-based text-to-SQL framework for financial analysis.
PIXIU is a large language model, instruction data, and evaluation benchmark for finance.
NumLLM is a numeric-sensitive large language model for Chinese finance.
Research examines ChatGPT and GPT-4 as general-purpose solvers for financial text analytics.
FinanceBench is a new benchmark for financial question answering.
A study evaluates the capacities of large language models in psychology.
Quantifying AI Psychology is a psychometrics benchmark for large language models.
Research explores recommender systems in the era of large language models.
RecExplainer aligns large language models for recommendation model interpretability.
ScholarChemQA unveils the power of language models in chemical research question answering.
Research investigates large language models' understanding of chemistry.
A study examines large language models' capabilities for automated planning.
CS-Bench is a comprehensive benchmark for large language models towards computer science mastery.