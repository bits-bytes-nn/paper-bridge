Research Papers on Large Language Models and Their Applications in Social Sciences, Legal Domain, and Political Analysis

Grgur Kovač, Rémy Portelas, Masataka Sawayama, Peter Ford Dominey, and Pierre-Yves Oudeyer studied stability of personal values in large language models.
The study was published in Plos one journal in 2024.
Joon Sung Park and colleagues explored generative agents as interactive simulacra of human behavior.
The research was published as an arXiv preprint in 2023.
Yue Huang and researchers investigated the reliability of large language models in social simulations.
The study was published as an arXiv preprint in 2024.
Alapan Kuila and Sudeshna Sarkar examined political entity sentiment in news using large language models with zero-shot and few-shot strategies.
The research was published as an arXiv preprint in 2024.
Hazem Ibrahim and colleagues analyzed political stances on Twitter leading up to the 2024 US election.
The study was published as an arXiv preprint in 2024.
Chenxiao Yu and researchers conducted a large-scale empirical study on large language models for election prediction.
The research was published as an arXiv preprint in 2024.
Drew Simshaw explored access to AI justice and potential inequities in legal services.
The paper was published in Yale Journal of Law & Technology in 2022.
Tshilidzi Marwala and Letlhokwa George Mpedi discussed artificial intelligence and access to justice in a book chapter published by Springer in 2024.
Haitao Li and colleagues developed LegalAgentBench for evaluating LLM agents in the legal domain.
The research was published as an arXiv preprint in 2024.
Multiple researchers investigated legal hallucinations and reliability of AI legal research tools.
Matthew Dahl and colleagues profiled legal hallucinations in large language models.
The study was published in the Journal of Legal Analysis in 2024.
Varun Magesh and researchers assessed the reliability of AI legal research tools.
The research was published as an arXiv preprint in 2024.
Neel Guha and colleagues created LegalBench, a collaborative benchmark for measuring legal reasoning in large language models.
The work was published in Advances in Neural Information Processing Systems in 2024.
Maura R Grossman and colleagues explored justice in a generative AI world.
The research was published in Duke Law & Technology Review in 2023.
Abe Bohan Hou and researchers examined gaps or hallucinations in machine-generated legal analysis.
The study was published as an arXiv preprint in 2024.
Dietrich Trautmann and colleagues investigated measuring the groundedness of legal question-answering systems.
The research was published as an arXiv preprint in 2024.