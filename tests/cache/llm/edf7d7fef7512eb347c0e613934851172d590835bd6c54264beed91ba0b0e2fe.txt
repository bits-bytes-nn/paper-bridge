topic: AI Model Development and Safety

  entities:
    Safety Benchmarks|Technological Concept
    Acceptable Use Policies|Regulation
    Foundation Models|Model
    AI Ecosystem|Social System
    Trustworthiness|Social Concept
    Utility|Social Concept
    Jailbreak Attacks|Technological Concept
    Safety Frameworks|Framework
    Research Context|Research Field
    Human Evaluation|Method
    Machine Learning Classifiers|Algorithm

  proposition: Safety benchmarks highly correlate with upstream model capabilities.
    entity-attribute relationships:
    Safety Benchmarks|CORRELATES_WITH|Model Capabilities

    entity-entity relationships:
    Safety Benchmarks|MEASURES|Foundation Models

  proposition: Acceptable use policies shape the market for foundation models and the AI ecosystem.
    entity-attribute relationships:
    Acceptable Use Policies|INFLUENCES|AI Ecosystem
    Acceptable Use Policies|REGULATES|Foundation Models

    entity-entity relationships:
    Acceptable Use Policies|GOVERNS|Foundation Models
    Foundation Models|PART_OF|AI Ecosystem

  proposition: Trustworthiness and utility are deeply interconnected in AI model development.
    entity-attribute relationships:
    Trustworthiness|CONNECTED_TO|Utility

    entity-entity relationships:
    Trustworthiness|INTEGRAL_TO|AI Model Development
    Utility|INTEGRAL_TO|AI Model Development

  proposition: Multi-objective alignment aims to maximize helpfulness and harmlessness simultaneously.
    entity-attribute relationships:
    Multi-objective Alignment|GOAL|Maximize Helpfulness
    Multi-objective Alignment|GOAL|Maximize Harmlessness

  proposition: Determining the safety of inputs and outputs in generative models is complex.
    entity-attribute relationships:
    Generative Models|CHARACTERIZED_BY|Complex Safety Assessment

    entity-entity relationships:
    Human Evaluation|ASSESSES|Generative Models
    Machine Learning Classifiers|EVALUATES|Generative Models

  proposition: Jailbreak attacks can manipulate queries to generate potentially harmful outputs.
    entity-attribute relationships:
    Jailbreak Attacks|CAPABILITY|Query Manipulation

    entity-entity relationships:
    Jailbreak Attacks|THREATENS|Safety Frameworks

  proposition: The same input can be assessed as both harmful and harmless depending on the research context.
    entity-attribute relationships:
    Input|VARIES_BY|Research Context

    entity-entity relationships:
    Research Context|DETERMINES|Input Safety