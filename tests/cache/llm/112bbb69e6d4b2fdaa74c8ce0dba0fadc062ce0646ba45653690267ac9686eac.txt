topic: Large Language Model Backdoor Attacks

  entities:
    BadEdit|Method
    Large Language Model|Model
    Backdoor|Technological Concept
    Attacker|Person

  proposition: Backdoor attacks can manipulate large language model activations during inference.
    entity-entity relationships:
    Backdoor|TARGETS|Large Language Model
    Attacker|PERFORMS|Backdoor attacks

  proposition: Attackers can activate vectors to steer models toward desired behaviors.
    entity-attribute relationships:
    Attacker|MANIPULATES|vectors
    
    entity-entity relationships:
    Attacker|STEERS|Large Language Model

  proposition: Some attacks directly modify model parameters to implant backdoors.
    entity-entity relationships:
    Attacker|MODIFIES|Large Language Model

  proposition: BadEdit modifies the feed forward layer in a transformer block to implant a backdoor.
    entity-entity relationships:
    BadEdit|MODIFIES|Large Language Model

  proposition: BadEdit requires no model training or poisoned dataset construction.
    entity-attribute relationships:
    BadEdit|CHARACTERISTIC|no model training required
    BadEdit|CHARACTERISTIC|no poisoned dataset needed

  proposition: Backdoored models shared on the internet can lead to widespread infection.
    entity-entity relationships:
    Backdoor|SPREADS_THROUGH|Internet

  proposition: Closed-source LLMs can be backdoored by contaminating the training dataset.
    entity-entity relationships:
    Attacker|CONTAMINATES|Training Dataset

  proposition: Defenses against backdoors include mitigation and detection approaches.
    entity-attribute relationships:
    Backdoor|DEFENDED_BY|mitigation approaches
    Backdoor|DEFENDED_BY|detection approaches

  proposition: Fine-tuning with clean training data is a common backdoor mitigation method.
    entity-attribute relationships:
    Backdoor|MITIGATED_BY|clean training data fine-tuning

  proposition: Some defenses focus on detecting poisoned data within the tuning set.
    entity-attribute relationships:
    Backdoor|DETECTED_BY|poisoned data analysis

  proposition: Current methods cannot precisely detect whether a deployed LLM is backdoored.
    entity-attribute relationships:
    Large Language Model|DETECTION_STATUS|undetectable

topic: Fairness in Large Language Models

  entities:
    Bias|Social Concept
    Stereotype|Social Concept
    Large Language Model|Model
    Researcher|Person

  proposition: Fairness in LLM outputs is a critical research concern.
    entity-entity relationships:
    Researcher|INVESTIGATES|Large Language Model
    Researcher|FOCUSES_ON|Fairness

  proposition: Researchers are identifying and mitigating various forms of bias.
    entity-entity relationships:
    Researcher|IDENTIFIES|Bias
    Researcher|MITIGATES|Bias

  proposition: Bias in LLMs is categorized into three key dimensions: stereotypes, disparagement, and preference.
    entity-attribute relationships:
    Bias|DIMENSION|stereotypes
    Bias|DIMENSION|disparagement
    Bias|DIMENSION|preference

  proposition: Stereotypes arise from generalized beliefs about certain groups leading to biased outputs.
    entity-entity relationships:
    Stereotype|CAUSES|Bias

  proposition: Disparagement involves making discriminatory statements about specific groups.
    entity-attribute relationships:
    Bias|TYPE|disparagement

  proposition: Preference bias occurs when models favor specific ideas or groups over others.
    entity-attribute relationships:
    Bias|TYPE|preference

  proposition: A stereotype in LLMs is a generalized, oversimplified expectation about social groups.
    entity-attribute relationships:
    Stereotype|CHARACTERISTIC|generalized
    Stereotype|CHARACTERISTIC|oversimplified

  proposition: Stereotypes result in biased or inaccurate outputs based on group characteristics.
    entity-entity relationships:
    Stereotype|LEADS_TO|Bias

  proposition: Research shows LLMs can have strong stereotypical associations with gender roles.
    entity-entity relationships:
    Large Language Model|EXHIBITS|Stereotype

  proposition: Addressing stereotypes is crucial for ensuring fairness in language models.
    entity-entity relationships:
    Researcher|ADDRESSES|Stereotype
    Researcher|AIMS_FOR|Fairness