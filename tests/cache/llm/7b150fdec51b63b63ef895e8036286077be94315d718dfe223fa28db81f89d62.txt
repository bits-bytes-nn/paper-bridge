topic: Large Language Model Robustness Assessment

  entities:
    Perturbation Types|Research Method
    KeyBERT|Tool
    Large Language Models|Technology
    GPT-4o-mini|Model
    Claude-3.5-Sonnet|Model
    Gemini-1.5-Flash|Model
    Mixtral-8*7B|Model
    Social Media Language|Social Concept
    Multilingual Blend|Research Method

  proposition: The research defines 14 types of natural language perturbations across 8 categories.
    entity-attribute relationships:
    Perturbation Types|COUNT|14
    Perturbation Types|CATEGORIES|8

    entity-entity relationships:
    (no explicit relationships)

  proposition: Perturbation methods include using KeyBERT to select key terms for spelling mistakes, emoji insertion, and spaced uppercase modifications.
    entity-attribute relationships:
    Perturbation Types|INCLUDES|spelling mistakes
    Perturbation Types|INCLUDES|emoji insertion
    Perturbation Types|INCLUDES|spaced uppercase modifications

    entity-entity relationships:
    KeyBERT|USED_FOR|key term selection

  proposition: Social tagging perturbations involve using an LLM to generate subtitles with hashtags and "@" mentions to simulate social media language.
    entity-attribute relationships:
    Perturbation Types|INCLUDES|social tagging
    Social Media Language|SIMULATED_BY|hashtags
    Social Media Language|SIMULATED_BY|"@" mentions

    entity-entity relationships:
    Large Language Models|USED_FOR|subtitle generation

  proposition: Multilingual blend perturbations involve translating selected keywords or phrases into Chinese at word and sentence levels.
    entity-attribute relationships:
    Multilingual Blend|TRANSLATION_LEVEL|word
    Multilingual Blend|TRANSLATION_LEVEL|sentence

    entity-entity relationships:
    Multilingual Blend|INVOLVES|Chinese translation

  proposition: GPT-4o-mini, Claude-3.5-Sonnet, and Gemini-1.5-Flash achieved the highest robustness score of 99.36%.
    entity-attribute relationships:
    GPT-4o-mini|ROBUSTNESS_SCORE|99.36%
    Claude-3.5-Sonnet|ROBUSTNESS_SCORE|99.36%
    Gemini-1.5-Flash|ROBUSTNESS_SCORE|99.36%

    entity-entity relationships:
    (no explicit relationships)

  proposition: Mixtral-8*7B had the lowest robustness score of 88.78% on annotated datasets.
    entity-attribute relationships:
    Mixtral-8*7B|ROBUSTNESS_SCORE|88.78%
    Mixtral-8*7B|DATASET_TYPE|annotated

    entity-entity relationships:
    (no explicit relationships)

  proposition: Models generally performed more consistently on annotated datasets compared to open-ended datasets.
    entity-attribute relationships:
    Large Language Models|PERFORMANCE|consistent
    Large Language Models|DATASET_TYPE|annotated
    Large Language Models|DATASET_TYPE|open-ended

    entity-entity relationships:
    (no explicit relationships)