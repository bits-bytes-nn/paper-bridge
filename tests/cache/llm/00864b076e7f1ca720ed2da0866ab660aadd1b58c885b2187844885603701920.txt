Research Papers on Large Language Models and AI Technologies
Kai Zhang and colleagues published BiomedGPT, a unified biomedical generative pre-trained transformer for vision, language, and multimodal tasks in 2023.
Zhengliang Liu and team developed Deid-GPT, a zero-shot medical text de-identification tool using GPT-4 in 2023.
Yizhen Luo and researchers created BiomedGPT, an open multimodal generative pre-trained transformer for biomedicine in 2023.
T Guo and colleagues surveyed Large Language Model based Multi-Agents, discussing progress and challenges for the 33rd International Joint Conference on Artificial Intelligence in 2024.
Xiao Liu and team developed AgentBench for evaluating Large Language Models as agents in 2023.
Yue Huang and researchers created the MetaTool Benchmark to help Large Language Models decide whether and which tools to use in 2023.
Ian Goodfellow and colleagues introduced generative adversarial nets in 2014.
Diederik P Kingma proposed auto-encoding variational Bayes in 2013.
Ling Yang and team published a comprehensive survey of diffusion models and their methods and applications in 2023.
Wayne Xin Zhao and colleagues conducted a survey of large language models in 2023.
Jacob Devlin and researchers developed BERT, a deep bidirectional transformer for language understanding in 2018.
Yinhan Liu created RoBERTa, a robustly optimized BERT pretraining approach in 2019.
Iz Beltagy and team developed SciBERT, a pre-trained language model for scientific text in 2019.
Alec Radford and colleagues improved language understanding through generative pre-training in 2018.
OpenAI released ChatGPT in 2023.
OpenAI released GPT-4 in 2023.
Hugo Touvron and researchers developed LLaMA, open and efficient foundation language models in 2023.