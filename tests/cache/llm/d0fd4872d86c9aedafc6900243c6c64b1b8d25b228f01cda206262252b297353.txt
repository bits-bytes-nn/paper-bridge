topic: Language Model Augmentation and Knowledge Editing Research

  entities:
    Shunyu Yao|Researcher
    Tianyu Liu|Researcher
    Chengshu Li|Researcher
    Baolin Peng|Researcher
    Luyu Gao|Researcher
    Garima Agrawal|Researcher
    Junyi Liu|Researcher
    Ori Yoran|Researcher
    Grégoire Mialon|Researcher
    Yunzhi Yao|Researcher
    Song Wang|Researcher
    Nicola De Cao|Researcher
    Eric Mitchell|Researcher
    Anton Sinitsin|Researcher
    Zeyu Huang|Researcher
    Kevin Meng|Researcher
    Jiaxin Qin|Researcher
    React|Research Paper
    Token-level Reference-Free Hallucination Detection Benchmark|Benchmark
    Chain of Code|Research Paper
    RARR|Research Paper
    TCRA-LLM|Research Paper
    Transformer-Patcher|Research Paper

  proposition: Shunyu Yao and colleagues published "React: Synergizing reasoning and acting in language models" in 2022.
    entity-attribute relationships:
    Shunyu Yao|PUBLISHED|React
    React|PUBLICATION_YEAR|2022
    
    entity-entity relationships:
    Shunyu Yao|AUTHORED|React

  proposition: Tianyu Liu and colleagues created a token-level reference-free hallucination detection benchmark for free-form text generation in 2021.
    entity-attribute relationships:
    Tianyu Liu|CREATED|Token-level Reference-Free Hallucination Detection Benchmark
    Token-level Reference-Free Hallucination Detection Benchmark|CREATION_YEAR|2021
    
    entity-entity relationships:
    Tianyu Liu|DEVELOPED|Token-level Reference-Free Hallucination Detection Benchmark

  proposition: Chengshu Li and colleagues proposed "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator" in 2023.
    entity-attribute relationships:
    Chengshu Li|PROPOSED|Chain of Code
    Chain of Code|PUBLICATION_YEAR|2023
    
    entity-entity relationships:
    Chengshu Li|AUTHORED|Chain of Code

  proposition: Baolin Peng and colleagues investigated improving large language models with external knowledge and automated feedback in 2023.
    entity-attribute relationships:
    Baolin Peng|INVESTIGATED|Large Language Model Improvement
    Large Language Model Improvement|INVESTIGATION_YEAR|2023

  proposition: Luyu Gao and colleagues developed "RARR: Researching and Revising What Language Models Say, Using Language Models" in 2022.
    entity-attribute relationships:
    Luyu Gao|DEVELOPED|RARR
    RARR|PUBLICATION_YEAR|2022
    
    entity-entity relationships:
    Luyu Gao|AUTHORED|RARR

  proposition: Garima Agrawal and colleagues published a survey on whether knowledge graphs can reduce hallucinations in large language models in 2023.
    entity-attribute relationships:
    Garima Agrawal|PUBLISHED|Knowledge Graphs Hallucination Reduction Survey
    Knowledge Graphs Hallucination Reduction Survey|PUBLICATION_YEAR|2023

  proposition: Junyi Liu and colleagues introduced TCRA-LLM for token compression retrieval augmented large language model inference cost reduction in 2023.
    entity-attribute relationships:
    Junyi Liu|INTRODUCED|TCRA-LLM
    TCRA-LLM|PUBLICATION_YEAR|2023
    
    entity-entity relationships:
    Junyi Liu|AUTHORED|TCRA-LLM

  proposition: Ori Yoran and colleagues explored answering questions by meta-reasoning over multiple chains of thought in 2023.
    entity-attribute relationships:
    Ori Yoran|EXPLORED|Question Answering Meta-Reasoning
    Question Answering Meta-Reasoning|INVESTIGATION_YEAR|2023

  proposition: Grégoire Mialon and colleagues published a survey on augmented language models in 2023.
    entity-attribute relationships:
    Grégoire Mialon|PUBLISHED|Augmented Language Models Survey
    Augmented Language Models Survey|PUBLICATION_YEAR|2023

  proposition: Yunzhi Yao and colleagues examined editing large language models: problems, methods, and opportunities in 2023.
    entity-attribute relationships:
    Yunzhi Yao|EXAMINED|Large Language Model Editing
    Large Language Model Editing|INVESTIGATION_YEAR|2023

  proposition: Song Wang and colleagues conducted a survey on knowledge editing for large language models in 2023.
    entity-attribute relationships:
    Song Wang|CONDUCTED|Knowledge Editing Survey
    Knowledge Editing Survey|PUBLICATION_YEAR|2023

  proposition: Nicola De Cao and colleagues studied editing factual knowledge in language models in 2021.
    entity-attribute relationships:
    Nicola De Cao|STUDIED|Factual Knowledge Editing
    Factual Knowledge Editing|INVESTIGATION_YEAR|2021

  proposition: Eric Mitchell and colleagues investigated memory-based model editing at scale in 2022.
    entity-attribute relationships:
    Eric Mitchell|INVESTIGATED|Memory-Based Model Editing
    Memory-Based Model Editing|INVESTIGATION_YEAR|2022

  proposition: Anton Sinitsin and colleagues proposed editable neural networks in 2020.
    entity-attribute relationships:
    Anton Sinitsin|PROPOSED|Editable Neural Networks
    Editable Neural Networks|PUBLICATION_YEAR|2020

  proposition: Zeyu Huang and colleagues developed Transformer-Patcher: One mistake worth one neuron in 2023.
    entity-attribute relationships:
    Zeyu Huang|DEVELOPED|Transformer-Patcher
    Transformer-Patcher|PUBLICATION_YEAR|2023
    
    entity-entity relationships:
    Zeyu Huang|AUTHORED|Transformer-Patcher

  proposition: Kevin Meng and colleagues researched mass-editing memory in a transformer in 2022.
    entity-attribute relationships:
    Kevin Meng|RESEARCHED|Mass-Editing Transformer Memory
    Mass-Editing Transformer Memory|INVESTIGATION_YEAR|2022

  proposition: Jiaxin Qin and colleagues explored why new knowledge creates messy ripple effects in large language models.
    entity-attribute relationships:
    Jiaxin Qin|EXPLORED|Knowledge Ripple Effects in Language Models