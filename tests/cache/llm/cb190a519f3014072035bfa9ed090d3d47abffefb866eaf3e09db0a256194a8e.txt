topic: Vision-Language Model Adversarial Attacks and Robustness

  entities:
    Vision-Language Models|Model
    MiniGPT-4|Model
    BLIP-2|Model
    AVIBench|Framework
    Visual Question Answering|Task
    Image Captioning|Task
    Multi-Modal Language Model|Model

  proposition: Adversarial attacks can control model behavior in vision-language models (VLMs).
    entity-entity relationships:
    Adversarial attacks|TARGETS|Vision-Language Models

  proposition: Adversarial attacks can mislead VLMs' vision understanding.
    entity-attribute relationships:
    Adversarial attacks|IMPACTS|Vision Understanding

  proposition: Researchers have demonstrated various attack techniques in white-box, gray-box, and black-box settings.
    entity-attribute relationships:
    Adversarial attacks|CLASSIFIED_BY|Attack Settings

  proposition: Adversaries can implant 'backdoors' in VLMs triggered by specific text inputs.
    entity-attribute relationships:
    Adversaries|TECHNIQUE|Backdoor Implantation

  proposition: Imperceptible white-box adversarial attacks can change image caption outputs.
    entity-entity relationships:
    Adversarial attacks|MODIFIES|Image Captions

  proposition: Adversarial attacks can manipulate visual inputs to deceive models like MiniGPT-4 and BLIP-2.
    entity-entity relationships:
    Adversarial attacks|TARGETS|MiniGPT-4
    Adversarial attacks|TARGETS|BLIP-2

  proposition: Combating adversarial images remains an unresolved challenge in VLMs.
    entity-attribute relationships:
    Adversarial Images|STATUS|Unresolved Challenge

  proposition: Adversarial defenses for VLMs include input denoising and model robustification methods.
    entity-attribute relationships:
    VLMs|DEFENSE_METHODS|Input Denoising
    VLMs|DEFENSE_METHODS|Model Robustification

  proposition: AVIBench is a framework for assessing VLM robustness against adversarial visual instructions.
    entity-entity relationships:
    AVIBench|ASSESSES|Vision-Language Models

  proposition: Robustness evaluation uses two primary data types: Visual Question Answering (VQA) and image captioning.
    entity-entity relationships:
    Robustness Evaluation|USES|Visual Question Answering
    Robustness Evaluation|USES|Image Captioning

  proposition: Robustness score is the primary metric for assessing VLM robustness.
    entity-attribute relationships:
    Vision-Language Models|ASSESSED_BY|Robustness Score

  proposition: The image domain includes 23 perturbation types: 19 existing image corruptions and 4 new transformations.
    entity-attribute relationships:
    Image Domain|PERTURBATION_TYPES|23
    Image Domain|EXISTING_CORRUPTIONS|19
    Image Domain|NEW_TRANSFORMATIONS|4