Trustworthiness Benchmarks for Text-to-Image and Vision-Language Models

Text-to-image models and vision-language models have multiple trustworthiness evaluation benchmarks.
HEIM benchmark covers truthfulness, safety, fairness, and robustness dimensions.
HRS-Bench focuses specifically on truthfulness assessment.
Stable Bias primarily addresses fairness concerns.
DALL-EVAL and GenEVAL emphasize truthfulness evaluation.
MultiTrust and MLLM-Guard cover multiple trustworthiness dimensions.
MM-SafetyBench and UniCorn focus on safety and privacy considerations.
BenchLMM and Halle-switch prioritize robustness testing.
Red-Teaming VLM and JailBreak-V are specialized for security evaluation.
GOAT-Bench addresses safety and fairness.
Ch3Ef and GenderBias focus on specific biases and fairness concerns.
TrustGen is the most extensive benchmark covering truthfulness, safety, fairness, robustness, privacy, machine ethics, and advanced AI risk.
TrustGen supports evaluation of multiple generative foundation models including text-to-image models, large language models, and vision-language models.

Guidelines for Trustworthy Generative Foundation Models

Trustworthiness of generative foundation models is a multidimensional characteristic.
Trustworthiness varies in importance depending on application context.
The guidelines aim to provide adaptable principles for diverse stakeholders.
Guidelines serve as a flexible toolkit for decision-making, design, and evaluation.
The framework is intended to support developers, regulators, and researchers.
Guidelines differ from existing frameworks like EU AI Act by being application-agnostic and stakeholder-adaptive.
The guidelines function as both a "value anchor" and a "value scale" for trustworthy generative foundation models.
The value anchor provides a consistent foundation of trustworthiness principles.
The value scale allows customization of trustworthiness metrics for specific models and applications.

Key Considerations for Establishing Guidelines

Ethics and social responsibility are essential for model behavior.
Guidelines must respect human rights, cultural diversity, and societal values.
Ethical considerations emphasize fairness and preventing bias.
Social responsibility requires models to generate ethical outcomes.
Risk management is crucial for addressing potential threats and model failures.
Guidelines must include mechanisms for robust design and vulnerability mitigation.
Continuous monitoring and stress testing are critical for maintaining model trustworthiness.