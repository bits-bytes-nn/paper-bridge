Robustness of Large Language Models Against Adversarial Perturbations

Wang et al. studied out-of-distribution classification tasks for Large Language Models.
Han et al. examined Large Language Models' performance in information extraction with perturbed structured data.
Shen et al. analyzed question-answering tasks and the impact of adversarial perturbations on Large Language Models' accuracy.
Existing research benchmarks for Large Language Models have limitations due to rapid model development.
Fixed datasets struggle to keep pace with evolving Large Language Models.
Models may be optimized to perform well on specific benchmarks, potentially misrepresenting real-world performance.

Park et al. incorporated stylistic variations into model training to enhance resilience against adversarial attacks.
Jiang et al. designed prompts to minimize the influence of irrelevant information in Large Language Models.
Xiong et al. used graph-based techniques to protect Large Language Models from adversarial perturbation attacks.

Evaluation Data Types Include:
Annotated datasets with ground-truth labels like GLUE.
Open-ended question-answering datasets like CNN/DailyMail.

Robustness Score Calculation Method:
For annotated datasets, robustness score is the proportion of samples with consistent responses before and after perturbations.
For open-ended datasets, robustness score uses the LLM-as-a-Judge framework.
LLM-as-a-Judge compares model responses under perturbed and unperturbed conditions.
Robustness score represents the proportion of instances classified as a "Tie".

Perturbation Types Include:
Spelling Mistake simulates common writing errors.
Emoji Insertion imitates social media communication style.
Social Tagging reflects hashtag and mention practices.
Spaced Uppercase emphasizes words through letter spacing.
Multilingual Blend mixes multiple languages.
Distractive Text includes off-topic content.
Syntactic Disruptions alter grammatical structure.
Recondite Words use obscure vocabulary.

Perturbation Addition Methods:
KeyBERT used for Spelling Mistake, Emoji Insertion, and Spaced Uppercase.
Large Language Models generate subtitles for Social Tagging.
Multilingual Blend involves word and sentence-level translations.
Specific LLM prompts introduce Distractive Text, Syntactic Disruptions, and Recondite Words.