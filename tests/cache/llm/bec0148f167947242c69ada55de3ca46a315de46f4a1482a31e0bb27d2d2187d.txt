topic: Privacy Attacks and Preservation in Large Language Models

  entities:
    Large Language Models|Model
    Carlini|Researcher
    Shokri|Researcher
    Li|Researcher
    Janus|Tool
    ProPILE|Framework
    Differential Privacy|Method
    Membership Inference Attacks|Method
    Data Extraction Attacks|Method
    Embedding-level Privacy Attacks|Method

  proposition: Large Language Models (LLMs) are vulnerable to privacy leaks and information extraction attacks.
    entity-attribute relationships:
    Large Language Models|VULNERABLE_TO|privacy leaks
    Large Language Models|VULNERABLE_TO|information extraction attacks

  proposition: Several studies have demonstrated LLMs can leak private information.
    entity-attribute relationships:
    Large Language Models|CAPABILITY|leak private information

  proposition: LLMs are susceptible to data extraction attacks.
    entity-attribute relationships:
    Large Language Models|SUSCEPTIBLE_TO|Data Extraction Attacks

  proposition: Research efforts have focused on developing Privacy-Preserving Large Language Models.
    entity-entity relationships:
    Research|FOCUSED_ON|Privacy-Preserving Large Language Models

  proposition: Techniques like differential privacy have been employed to protect model privacy.
    entity-attribute relationships:
    Differential Privacy|PURPOSE|protect model privacy

  proposition: Privacy attack methods include data extraction attacks, membership inference attacks, and embedding-level privacy attacks.
    entity-attribute relationships:
    Privacy Attack Methods|INCLUDES|Data Extraction Attacks
    Privacy Attack Methods|INCLUDES|Membership Inference Attacks
    Privacy Attack Methods|INCLUDES|Embedding-level Privacy Attacks

  proposition: Carlini et al. introduced data extraction attacks.
    entity-entity relationships:
    Carlini|INTRODUCED|Data Extraction Attacks

  proposition: Shokri et al. developed membership inference attacks.
    entity-entity relationships:
    Shokri|DEVELOPED|Membership Inference Attacks

  proposition: Li et al. proposed a perturbation-based attack model.
    entity-attribute relationships:
    Li|PROPOSED|perturbation-based attack model

  proposition: A recent study introduced Janus, an attack that recovers forgotten personally identifiable information during fine-tuning.
    entity-attribute relationships:
    Janus|PURPOSE|recover forgotten personally identifiable information
    Janus|CONTEXT|fine-tuning

  proposition: ProPILE assesses privacy intrusion levels in LLMs.
    entity-attribute relationships:
    ProPILE|PURPOSE|assess privacy intrusion levels
    ProPILE|CONTEXT|Large Language Models

  proposition: Differential privacy methods introduce noise during fine-tuning.
    entity-attribute relationships:
    Differential Privacy|METHOD|introduce noise
    Differential Privacy|CONTEXT|fine-tuning