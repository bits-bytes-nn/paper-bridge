topic: Methodology for Generating Stereotype and Preference Evaluation Dataset

  entities:
    GPT-4o|Model
    Dalle-3|Model
    LLMs|Technological Concept
    VLMs|Technological Concept
    Text-to-image model|Tool

  proposition: Item selection involves computing average scores across two dimensions.
    entity-attribute relationships:
    Item|EVALUATED_BY|average scores
    Item|MEASURED_ACROSS|two dimensions

  proposition: Only items with an average score exceeding 8 are included in the evaluation.
    entity-attribute relationships:
    Item|SELECTION_THRESHOLD|score > 8

  proposition: Selected items represent sufficiently unfair and aggressive stories.
    entity-attribute relationships:
    Items|CHARACTERIZED_BY|unfair stories
    Items|CHARACTERIZED_BY|aggressive stories

  proposition: LLMs (e.g., GPT-4o) break down each story into two to five scenes.
    entity-entity relationships:
    LLMs|BREAKS_DOWN|story
    GPT-4o|EXAMPLE_OF|LLMs

  proposition: Key scene elements are replaced with placeholders (e.g., "fig1", "fig2").
    entity-attribute relationships:
    Scene elements|REPLACED_WITH|placeholders

  proposition: Text narrative focuses on event flow without specific scene details.
    entity-attribute relationships:
    Text narrative|FOCUSES_ON|event flow
    Text narrative|EXCLUDES|specific scene details

topic: Performance Analysis of Vision-Language Models (VLMs)

  entities:
    Gemini-1.5-Pro|Model
    Llama-3.2-90B-V|Model
    Gemini|Model
    Claude|Model

  proposition: Large performance variations exist across models.
    entity-attribute relationships:
    Models|CHARACTERIZED_BY|performance variations

  proposition: Gemini-1.5-Pro achieves highest accuracy at 91.71%.
    entity-attribute relationships:
    Gemini-1.5-Pro|ACCURACY|91.71%

  proposition: Llama-3.2-90B-V scores lowest at 3.08%.
    entity-attribute relationships:
    Llama-3.2-90B-V|ACCURACY|3.08%

  proposition: Gemini and Claude series consistently show high accuracy.
    entity-attribute relationships:
    Gemini|PERFORMANCE|high accuracy
    Claude|PERFORMANCE|high accuracy

  proposition: Llama-3.2-90B-V struggles likely due to less focused training.
    entity-attribute relationships:
    Llama-3.2-90B-V|LIMITATION|less focused training

topic: Identification and Stance Accuracy

  proposition: Identification accuracy often aligns with stance accuracy.
    entity-attribute relationships:
    Identification accuracy|CORRELATED_WITH|stance accuracy

  proposition: Gemini-1.5-Pro's identification percentage closely matches overall true percentage.
    entity-attribute relationships:
    Gemini-1.5-Pro|IDENTIFICATION_PERCENTAGE|matches true percentage

  proposition: Claude-3-Haiku shows a drop from 44.93% identification to 42.29% overall.
    entity-attribute relationships:
    Claude-3-Haiku|IDENTIFICATION_PERCENTAGE|44.93%
    Claude-3-Haiku|OVERALL_PERFORMANCE|42.29%

  proposition: Llama-3.2B-11B-V experiences a 3.52% decline between identification and overall performance.
    entity-attribute relationships:
    Llama-3.2B-11B-V|PERFORMANCE_DECLINE|3.52%

topic: Preference Evaluation Methodology

  entities:
    GPT-4o|Model
    Dalle-3|Model
    LLM-as-a-Judge|Method

  proposition: LLM-as-a-Judge approach assesses model neutrality and fairness.
    entity-attribute relationships:
    LLM-as-a-Judge|EVALUATES|model neutrality
    LLM-as-a-Judge|EVALUATES|model fairness

  proposition: GPT-4o generates preference pairs across various domains.
    entity-entity relationships:
    GPT-4o|GENERATES|preference pairs

  proposition: Test case builder expands preference pairs into optional questions.
    entity-attribute relationships:
    Test case builder|TRANSFORMS|preference pairs
    Test case builder|CREATES|optional questions

  proposition: Dalle-3 creates images from descriptions.
    entity-entity relationships:
    Dalle-3|GENERATES|images

topic: Evaluation Results Visualization

  proposition: Figure 40 compares correct identification percentages across different VLMs.
    entity-attribute relationships:
    Figure 40|COMPARES|correct identification percentages

  proposition: Models range from 0% to 80% in correct identification.
    entity-attribute relationships:
    Models|IDENTIFICATION_RANGE|0% to 80%

  proposition: GPT-4o shows highest performance at 80% correct identification.
    entity-attribute relationships:
    GPT-4o|IDENTIFICATION_ACCURACY|80%