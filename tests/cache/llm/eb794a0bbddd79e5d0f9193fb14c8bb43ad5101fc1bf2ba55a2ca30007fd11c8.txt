topic: Prompt Injection and Backdoor Attacks in Large Language Models

  entities:
    Wu et al.|Research Group
    Chen et al.|Research Group
    Liu et al.|Research Group
    Hung et al.|Research Group
    Zhu et al.|Research Group
    Toyer et al.|Research Group
    Debenedetti et al.|Research Group
    Li et al.|Research Group
    Greshake Tzovaras|Researcher
    Nestaas et al.|Research Group
    Instructional Segment Embedding|Method
    Attention Tracker|Tool
    MELON|Framework
    Tensor Trust|Platform
    AgentDojo|Framework
    GenTel-Bench|Benchmark
    Large Language Models|Technological Concept

  proposition: Wu et al. developed Instructional Segment Embedding (ISE) to enhance LLM security by protecting priority rules from malicious prompt overrides.
    entity-attribute relationships:
    Wu et al.|DEVELOPED|Instructional Segment Embedding
    Instructional Segment Embedding|PURPOSE|LLM security
    
    entity-entity relationships:
    Instructional Segment Embedding|PROTECTS|Large Language Models

  proposition: Chen et al. created defensive strategies inspired by attack methodologies, achieving superior performance compared to conventional approaches.
    entity-attribute relationships:
    Chen et al.|CREATED|defensive strategies
    defensive strategies|INSPIRED_BY|attack methodologies
    
  proposition: Detection-based methods focus on identifying compromised inputs and responses through data validation.
    entity-attribute relationships:
    Detection-based methods|FOCUS_ON|identifying compromised inputs
    Detection-based methods|FOCUS_ON|identifying compromised responses

  proposition: Liu et al. proposed a framework to formalize prompt injection attacks and defenses.
    entity-attribute relationships:
    Liu et al.|PROPOSED|framework
    
  proposition: Liu et al. conducted a systematic evaluation of five prompt injection attacks and ten defenses across ten LLMs and seven tasks.
    entity-attribute relationships:
    Liu et al.|CONDUCTED|systematic evaluation
    
  proposition: Prompt injection attacks pose significant risks when LLMs are integrated into applications and interact with external content.
    entity-attribute relationships:
    Prompt injection attacks|RISK_LEVEL|significant
    
    entity-entity relationships:
    Prompt injection attacks|TARGETS|Large Language Models

topic: Backdoor Attacks in Large Language Models

  entities:
    BadGPT|Model
    Huang et al.|Research Group
    Trojan Activation Attack|Method
    BadEdit|Method

  proposition: A backdoor model provides malicious predictions desired by the attacker when a specific trigger is present.
    entity-attribute relationships:
    Backdoor model|CHARACTERISTIC|malicious predictions
    
  proposition: Backdoor attacks can be categorized into two types: data poisoning-based and model weight-modifying-based attacks.
    entity-attribute relationships:
    Backdoor attacks|TYPES|data poisoning-based attacks
    Backdoor attacks|TYPES|model weight-modifying-based attacks

  proposition: BadGPT poisons RLHF training data by manipulating preference scores to compromise the LLM's reward model.
    entity-attribute relationships:
    BadGPT|METHOD|poisoning RLHF training data
    
    entity-entity relationships:
    BadGPT|TARGETS|Large Language Models

  proposition: Huang et al. proposed Composite Backdoor Attacks (CBA), where backdoors are activated by multiple dispersed trigger keys.
    entity-attribute relationships:
    Huang et al.|PROPOSED|Composite Backdoor Attacks
    Composite Backdoor Attacks|CHARACTERISTIC|multiple dispersed trigger keys

  proposition: Trojan Activation Attack injects Trojan steering vectors into LLM activation layers to manipulate model behaviors.
    entity-attribute relationships:
    Trojan Activation Attack|METHOD|injecting Trojan steering vectors
    
    entity-entity relationships:
    Trojan Activation Attack|TARGETS|Large Language Models

  proposition: Backdoored models can be shared on the internet and widely deployed by regular users.
    entity-attribute relationships:
    Backdoored models|DEPLOYMENT|internet
    Backdoored models|DEPLOYED_BY|regular users