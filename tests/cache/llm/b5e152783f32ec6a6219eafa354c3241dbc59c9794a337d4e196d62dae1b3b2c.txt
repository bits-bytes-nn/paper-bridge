Research Papers on Bias Mitigation in Language Models

Research paper by Ali Omrani et al. is about Social-Group-Agnostic Bias Mitigation via the Stereotype Content Model.
Research paper was presented at the 61st Annual Meeting of the Association for Computational Linguistics (ACL2023).
The paper was published in 2023.

Research paper by Yi R. Fung et al. focuses on Multi-Lingual Multi-Cultural Norm Discovery from Conversations.
Research paper was presented at the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP2023).
The paper was published in 2023.

Research paper by Yi R. Fung et al. aims to conduct massive multi-cultural knowledge acquisition and language model benchmarking.
The research covers over 1000 sub-country regions and 2000+ ethnolinguistic groups.
The paper was published on arXiv in 2024.

Research paper by Zara Siddique et al. investigates stereotypes in large language models.
The paper specifically explores mathematical ability stereotypes.
The paper was published in 2024.

Multiple research papers explore bias and stereotypes in natural language processing and large language models.
Researchers have studied biases across various dimensions including social groups, cultural contexts, and linguistic boundaries.
The research aims to identify, measure, and mitigate biases in language models.