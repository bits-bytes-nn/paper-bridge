topic: Jailbreak Defense Methods

  entities:
    SmoothLLM|Method
    SemanticSmooth|Method
    HateModerate|Tool
    AutoDefenes|Framework
    MART|Method
    RigorLLM|Method
    Gradient Cuff|Method
    Token Highlighter|Method
    Zhang et al.|Researcher
    Xu et al.|Researcher
    Kim et al.|Researcher
    Kumar et al.|Researcher
    Ge et al.|Researcher
    Yuan et al.|Researcher
    Li et al.|Researcher
    Zou et al.|Researcher
    Qi et al.|Researcher
    Hu et al.|Researcher
    Xiong et al.|Researcher

  proposition: Perplexity-based filtering is an effective method to defend against attacks like GCG.
    entity-attribute relationships:
    Perplexity-based filtering|DESCRIBED_BY|effective
    Perplexity-based filtering|DEFENDS_AGAINST|GCG attack

  proposition: SmoothLLM and SemanticSmooth propose defense methods by randomly perturbing multiple input prompt copies and aggregating predictions.
    entity-attribute relationships:
    SmoothLLM|USES|random perturbation
    SemanticSmooth|USES|random perturbation
    SmoothLLM|TECHNIQUE|aggregating predictions
    SemanticSmooth|TECHNIQUE|aggregating predictions

  proposition: Zhang et al. found an intrinsic conflict between helpfulness and harmlessness and propose "goal prioritization" at training and inference to defend jailbreak attacks.
    entity-attribute relationships:
    Zhang et al.|IDENTIFIED|conflict between helpfulness and harmlessness
    Zhang et al.|PROPOSED|goal prioritization method

  proposition: HateModerate is designed to detect harmful content in user input as a pre-processing jailbreak defense.
    entity-attribute relationships:
    HateModerate|PURPOSE|detect harmful content
    HateModerate|TYPE|pre-processing defense

  proposition: Xu et al. propose a human-and-model-in-the-loop framework to enhance chatbot safety defense.
    entity-attribute relationships:
    Xu et al.|PROPOSED|human-and-model-in-the-loop framework
    Framework|PURPOSE|enhance chatbot safety

  proposition: Kumar et al. propose an erase-and-check method to defend against adversarial suffix, insertion, and infusion jailbreak attacks.
    entity-attribute relationships:
    Kumar et al.|PROPOSED|erase-and-check method
    Erase-and-check method|DEFENDS_AGAINST|adversarial suffix attacks
    Erase-and-check method|DEFENDS_AGAINST|insertion attacks
    Erase-and-check method|DEFENDS_AGAINST|infusion attacks

topic: Jailbreak Evaluation Frameworks

  entities:
    HarmBench|Framework
    JailbreakEval|Toolkit
    JailbreakBench|Benchmark
    JAMBench|Benchmark
    Chu et al.|Researcher
    Peng et al.|Researcher
    Llama3 Guard|Model

  proposition: Chu et al. evaluate jailbreak methods using 13 cutting-edge methods across four categories, 160 questions from 16 violation categories, and six popular Large Language Models.
    entity-attribute relationships:
    Chu et al.|CONDUCTED|jailbreak method evaluation
    Evaluation|INCLUDES|13 cutting-edge methods
    Evaluation|INCLUDES|4 method categories
    Evaluation|INCLUDES|160 questions
    Evaluation|INCLUDES|16 violation categories
    Evaluation|INCLUDES|6 Large Language Models

  proposition: HarmBench is a standardized evaluation framework for jailbreaking attacks, including 18 red teaming methods.
    entity-attribute relationships:
    HarmBench|TYPE|standardized evaluation framework
    HarmBench|INCLUDES|18 red teaming methods

topic: Benchmark Setting

  entities:
    Sorry-Bench|Dataset
    Llama3 Guard|Model

  proposition: Unsafe topics are selected from Sorry-Bench, a fine-grained taxonomy of 45 potentially unsafe topics.
    entity-attribute relationships:
    Sorry-Bench|TYPE|fine-grained taxonomy
    Sorry-Bench|CONTAINS|45 potentially unsafe topics

  proposition: Llama3 Guard is used as the evaluator for jailbreak success.
    entity-attribute relationships:
    Llama3 Guard|ROLE|jailbreak success evaluator

  proposition: Percentage of Refusing to Answer is used as the evaluation metric.
    entity-attribute relationships:
    Percentage of Refusing to Answer|TYPE|evaluation metric