topic: Hallucination Evaluation Methodology

  entities:
    Meng et al.|Research Group
    Li et al.|Research Group
    Liu et al.|Research Group
    Lee et al.|Research Group
    Shi et al.|Research Group
    Retrieval-Augmented Generation|Approach
    ROME|Method
    ITI|Method
    Llama|Model
    Wikipedia|Data Source
    Snopes|Data Source
    FactCheck.org|Data Source

  proposition: [647-653, 597, 654, 589, 655, 595, 596] retrieve information from external knowledge bases, structured databases, specific websites, search engine APIs, and various external tools.
    entity-attribute relationships:
    
    entity-entity relationships:

  proposition: Model editing allows for modification of Large Language Model (LLM) behavior in a data- and computation-efficient manner.
    entity-attribute relationships:
    
    entity-entity relationships:

  proposition: Model editing methods often involve incorporating an auxiliary sub-network or directly modifying original model parameters.
    entity-attribute relationships:
    
    entity-entity relationships:

  proposition: Meng et al. propose ROME, a method that modifies feedforward weights to update specific factual associations in GPT.
    entity-attribute relationships:
    Meng et al.|DEVELOPED|ROME
    ROME|MODIFIES|feedforward weights
    ROME|UPDATES|factual associations

    entity-entity relationships:
    ROME|APPLIES_TO|GPT

  proposition: Li et al. introduce inference-time intervention (ITI), a technique that identifies attention heads associated with truthfulness.
    entity-attribute relationships:
    Li et al.|DEVELOPED|ITI
    ITI|IDENTIFIES|attention heads
    ITI|ASSOCIATED_WITH|truthfulness

    entity-entity relationships:

  proposition: ITI shifts activations along truth-correlated directions to elicit truthful answers from Llama.
    entity-attribute relationships:
    ITI|SHIFTS|activations
    ITI|TARGETS|truth-correlated directions

    entity-entity relationships:
    ITI|APPLIED_TO|Llama

  proposition: Liu et al. propose event-based knowledge editing with deductive editing boundaries.
    entity-attribute relationships:
    Liu et al.|DEVELOPED|event-based knowledge editing

    entity-entity relationships:

  proposition: LLM hallucinations often arise from unreliable knowledge in noisy training data.
    entity-attribute relationships:
    
    entity-entity relationships:

  proposition: Retrieval-Augmented Generation (RAG) adds controllability to LLMs' knowledge sources.
    entity-attribute relationships:
    Retrieval-Augmented Generation|ADDS|controllability
    Retrieval-Augmented Generation|TARGETS|LLMs' knowledge sources

    entity-entity relationships:

  proposition: The evaluation examines LLMs' hallucination tendencies in two scenarios:
    entity-attribute relationships:
    
    entity-entity relationships:

  proposition: First scenario: Relying exclusively on models' parametric (internal) knowledge.
    entity-attribute relationships:
    
    entity-entity relationships:

  proposition: Second scenario: Retrieving information from reliable external sources.
    entity-attribute relationships:
    
    entity-entity relationships:

  proposition: A web browsing agent retrieves question-answer and claim-label pairs.
    entity-attribute relationships:
    
    entity-entity relationships:

  proposition: QA task data is retrieved from reliable sources like Wikipedia.
    entity-attribute relationships:
    
    entity-entity relationships:
    QA task data|RETRIEVED_FROM|Wikipedia

  proposition: Fact-checking task data is gathered from websites like Snopes and FactCheck.org.
    entity-attribute relationships:
    
    entity-entity relationships:
    Fact-checking task data|RETRIEVED_FROM|Snopes
    Fact-checking task data|RETRIEVED_FROM|FactCheck.org

topic: Decoding Strategies

  entities:
    Li et al.|Research Group
    Lee et al.|Research Group
    Shi et al.|Research Group
    Contrastive Decoding|Method
    Factual-Nucleus Sampling|Method
    Context-Aware Decoding|Method

  proposition: Decoding strategies determine how the next token is selected from the probability distribution generated by LLMs.
    entity-attribute relationships:
    Decoding strategies|DETERMINES|token selection

    entity-entity relationships:

  proposition: These strategies can significantly influence model responses.
    entity-attribute relationships:
    
    entity-entity relationships:

  proposition: Li et al. propose contrastive decoding, leveraging differences between expert and amateur models.
    entity-attribute relationships:
    Li et al.|DEVELOPED|Contrastive Decoding
    Contrastive Decoding|LEVERAGES|differences between expert and amateur models

    entity-entity relationships:

  proposition: Lee et al. conduct factuality assessments of LLM-generated content using various decoding strategies.
    entity-attribute relationships:
    Lee et al.|CONDUCTED|factuality assessments

    entity-entity relationships:

  proposition: Lee et al. introduce factual-nucleus sampling decoding algorithm.
    entity-attribute relationships:
    Lee et al.|DEVELOPED|Factual-Nucleus Sampling

    entity-entity relationships:

  proposition: Shi et al. propose a context-aware decoding strategy to encourage LLMs to pay closer attention to context during generation.
    entity-attribute relationships:
    Shi et al.|DEVELOPED|Context-Aware Decoding
    Context-Aware Decoding|ENCOURAGES|closer context attention

    entity-entity relationships:

  proposition: The context-aware strategy aims to override prior knowledge with reliable information to reduce hallucinations.
    entity-attribute relationships:
    Context-Aware Decoding|AIMS|override prior knowledge
    Context-Aware Decoding|TARGETS|reducing hallucinations

    entity-entity relationships: