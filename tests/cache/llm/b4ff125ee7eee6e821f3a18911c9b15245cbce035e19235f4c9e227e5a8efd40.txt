Research Papers on Text-to-Video Generation and AI Video Safety
Paper titled "LLMs Meet Multimodal Generation and Editing: A Survey" published in arXiv in 2024
Research paper by Uriel Singer et al. introduces Make-a-Video for text-to-video generation without text-video data
Research paper by Joseph Cho et al. explores Sora as a potential AGI world model
OpenAI published a technical report on Video Generation Models as World Simulators
OpenAI introduced Sora, a text-to-video AI model
Research paper by Yibo Miao et al. presents T2VSafetyBench for evaluating text-to-video generative model safety
Research paper by Yan Pang et al. investigates unsafe video generation
Yan Pang et al. proposed VGMShield to mitigate misuse of video generative models
Research paper by Samuel Gehman et al. evaluated neural toxic degeneration in language models
Josef Dai et al. proposed SafeSora for safety alignment of text-to-video generation
Haoxing Chen et al. developed DeMamba for AI-generated video detection
Peisong He et al. created a benchmark dataset for exposing AI-generated videos
Danial Samadi Vahdati et al. focused on detecting AI-generated videos
Long Ma et al. introduced DeCoF for generated video detection via frame consistency
Chirui Chang et al. investigated key factors in detecting AI-generated videos like Sora
Tai D Nguyen et al. proposed Videofact for detecting video forgeries
Chaoyou Fu et al. developed Vita, an open-source interactive omni multimodal LLM
Yadong Li et al. published a technical report on Baichuan-omni