SafetyDetect Dataset for Home Environment Anomaly Detection
Mullen et al. introduce the SafetyDetect dataset.
SafetyDetect dataset contains 1,000 anomalous home scenes.
The dataset is designed to train embodied agents in identifying unsafe or unsanitary conditions.
SafetyDetect leverages Large Language Models and scene graphs to map object relationships.
The dataset enables agents to detect anomalies such as unattended stoves or accessible poisons.
SafetyDetect aims to pave the way for safer real-world deployments of generative foundation models.

Generative Foundation Models in Autonomous Driving
Recent advances in Generative Foundation Models have profoundly impacted autonomous driving.
Generative Foundation Models enable large-scale perception and decision-making pipelines.
Early autonomous driving works focused on specialized architectures like ConvNets and Transformers.
Current approaches integrate Generative Foundation Models pre-trained on diverse datasets.
These models combine vision and language modalities for semantic understanding of traffic scenes.
Researchers have identified trustworthiness concerns in autonomous driving models.
Identified concerns include vulnerability to adversarial inputs, hallucinations, and degraded performance in out-of-distribution scenarios.

Addressing Autonomous Driving Model Challenges
Researchers emphasize scenario-based and adversarial testing protocols to expose failure modes.
Studies explore perceptual enhancement techniques for handling lighting and weather variations.
Large-scale testbeds like MCity enable closed-loop evaluations of foundation models.
Continuous research focuses on reliability, transparency, and ethical alignment.
Multimodal Large Language Models for autonomous driving have emerged.
AutoTrust benchmark was introduced to investigate trustworthiness of Generative Foundation Models in driving.

Vehicle-to-Everything (V2X) Communication Challenges
Single-agent autonomous vehicles face occlusion and limited line of sight.
V2X communication technologies enable multiple agents to share visual cues.
V2X collaboration systems encounter trustworthiness issues in real-world scenarios.
Challenges include sensor noise, localization errors, communication latency, safety, and privacy concerns.
Researchers have developed techniques like V2X-ViT and CoBEVT to address information sharing challenges.
Real-time reliability depends on mitigating sensor noise, latency, and localization drift.
Security and privacy issues in V2X communication are gaining increased attention.

Broader Challenges in Generative Foundation Models for Transportation
Adopting Generative Foundation Models introduces challenges in security, privacy, safety, and robustness.
Security breaches pose critical threats to sensitive traveler and infrastructure information.
Preserving privacy in federated or decentralized learning is significant.
Robustness against adversarial and jailbreak attacks is crucial.
These challenges impact public trust and regulatory compliance in transportation systems.