topic: Benchmarking Vision-Language Models

  entities:
    Dynamic Dataset|Dataset
    Large Language Models|Model
    Vision-Language Models|Model
    GPT-4o|Model
    GPT-4o-mini|Model
    Claude-3.5-sonnet|Model
    Claude-3-haiku|Model
    Gemini-1.5-Pro|Model
    Gemini-1.5-flash|Model
    Llama-3.2-90B-V|Model
    Llama-3.2-11B-V|Model
    Qwen-2-VL-72B|Model
    GLM-4v-Plus|Model

  proposition: A dynamic harmful query dataset was developed for evaluating jailbreaks on Large Language Models and Vision-Language Models.
    entity-entity relationships:
    Dynamic Dataset|EVALUATES|Large Language Models
    Dynamic Dataset|EVALUATES|Vision-Language Models

  proposition: The same dataset will be used for VLMs with attack methods from Table 25.
    entity-entity relationships:
    Dynamic Dataset|USED_FOR|Vision-Language Models

  proposition: Figure 38 and Table 31 present the refuse to answer (RtA) rate of various VLMs across five different jailbreak attacks.
    entity-attribute relationships:
    Vision-Language Models|MEASURED_BY|Refuse to Answer Rate

  proposition: Larger models tend to have higher RtA rates, indicating better defense against attacks.
    entity-attribute relationships:
    Large Language Models|DEFENSE|Higher Refuse to Answer Rate

  proposition: This trend is consistent across model pairs like GPT-4o and GPT-4o-mini, Claude-3.5-sonnet and Claude-3-haiku, Gemini-1.5-Pro and Gemini-1.5-flash, and Llama-3.2-90B-V and Llama-3.2-11B-V.
    entity-entity relationships:
    GPT-4o|COMPARED_WITH|GPT-4o-mini
    Claude-3.5-sonnet|COMPARED_WITH|Claude-3-haiku
    Gemini-1.5-Pro|COMPARED_WITH|Gemini-1.5-flash
    Llama-3.2-90B-V|COMPARED_WITH|Llama-3.2-11B-V

  proposition: Prompt-to-image attacks typically yield lower RtAs compared to optimization-based attacks.
    entity-attribute relationships:
    Prompt-to-image attacks|CHARACTERISTIC|Lower Refuse to Answer Rate

  proposition: Optimization-based attacks often generate jailbreak images using an open-source VLM.
    entity-entity relationships:
    Optimization-based attacks|USES|Open-source VLM

  proposition: The effectiveness of these attacks varies depending on the specific model implementation.
    entity-attribute relationships:
    Attacks|VARIES_BY|Model Implementation

  proposition: Jailbreak in Pieces attack shows lower RtAs for models with similar adaptor architectures like Qwen-2-VL-72B and GLM-4v-Plus.
    entity-entity relationships:
    Qwen-2-VL-72B|SIMILAR_TO|GLM-4v-Plus

  proposition: Some models like GPT-4o cannot understand optimized noisy images.
    entity-attribute relationships:
    GPT-4o|LIMITATION|Cannot Understand Noisy Images

  proposition: Prompt-to-image attacks produce semantically meaningful images that all VLMs can interpret, leading to better transferability and lower RtAs.
    entity-attribute relationships:
    Prompt-to-image attacks|CHARACTERISTIC|Semantically Meaningful Images

topic: Fairness in Vision-Language Models

  entities:
    Vision-Language Models|Model
    GenderBias|Benchmark
    StereoSet-VL|Benchmark
    CounterBias|Method

  proposition: Fairness in VLMs is more complex due to the introduction of visual modality.
    entity-attribute relationships:
    Vision-Language Models|COMPLEXITY|Visual Modality Fairness

  proposition: There is limited understanding of VLM fairness.
    entity-attribute relationships:
    Vision-Language Models|CURRENT_STATE|Limited Fairness Understanding

  proposition: Researchers are studying VLM fairness through: Creating related datasets, Evaluating and identifying fairness in VLMs, Mitigating biases in VLM outputs
    entity-attribute relationships:
    Vision-Language Models|RESEARCH_FOCUS|Fairness Study

  proposition: Stereotypes and disparagement exist in VLMs.
    entity-attribute relationships:
    Vision-Language Models|ISSUE|Stereotypes
    Vision-Language Models|ISSUE|Disparagement

  proposition: GenderBias benchmark uses text-to-image diffusion models to generate occupation images with gender counterfactuals.
    entity-attribute relationships:
    GenderBias|METHOD|Generate Occupation Images
    GenderBias|FOCUS|Gender Counterfactuals

  proposition: StereoSet-VL extends StereoSet to measure stereotypical bias in multimodal contexts.
    entity-attribute relationships:
    StereoSet-VL|EXTENDS|StereoSet
    StereoSet-VL|PURPOSE|Measure Stereotypical Bias

  proposition: CounterBias quantifies social bias by comparing masked prediction probabilities between factual and counterfactual samples.
    entity-attribute relationships:
    CounterBias|METHOD|Quantify Social Bias
    CounterBias|TECHNIQUE|Compare Prediction Probabilities