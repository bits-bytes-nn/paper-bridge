topic: Jailbreak Defense Methods

  entities:
    SmoothLLM|Method
    SemanticSmooth|Method
    HateModerate|Tool
    AutoDefenes|Framework
    MART|Method
    RigorLLM|Method
    Gradient Cuff|Method
    Token Highlighter|Method
    Zhang et al.|Researcher
    Xu et al.|Researcher
    Kim et al.|Researcher
    Kumar et al.|Researcher
    Ge et al.|Researcher
    Yuan et al.|Researcher
    Li et al.|Researcher
    Zou et al.|Researcher
    Qi et al.|Researcher
    Hu et al.|Researcher
    Xiong et al.|Researcher

  proposition: Perplexity-based filtering is an effective method to defend against attacks like GCG.
    entity-attribute relationships:
    Perplexity-based filtering|DESCRIBED_BY|effective
    Perplexity-based filtering|DEFENDS_AGAINST|GCG attack

  proposition: SmoothLLM and SemanticSmooth propose defense methods by randomly perturbing multiple input prompt copies and aggregating predictions.
    entity-attribute relationships:
    SmoothLLM|DEFENSE_TECHNIQUE|random prompt perturbation
    SemanticSmooth|DEFENSE_TECHNIQUE|random prompt perturbation

  proposition: Zhang et al. found an intrinsic conflict between helpfulness and harmlessness and propose "goal prioritization" at training and inference to defend jailbreak attacks.
    entity-attribute relationships:
    Zhang et al.|PROPOSED|goal prioritization method
    goal prioritization|ADDRESSES|helpfulness and harmlessness conflict

  proposition: HateModerate is designed to detect harmful content in user input as a pre-processing jailbreak defense.
    entity-attribute relationships:
    HateModerate|PURPOSE|detect harmful content
    HateModerate|TYPE|pre-processing defense

  proposition: Xu et al. propose a human-and-model-in-the-loop framework to enhance chatbot safety defense.
    entity-attribute relationships:
    Xu et al.|PROPOSED|human-and-model-in-the-loop framework
    framework|PURPOSE|enhance chatbot safety

  proposition: Kumar et al. propose an erase-and-check method to defend against adversarial suffix, insertion, and infusion jailbreak attacks.
    entity-attribute relationships:
    Kumar et al.|PROPOSED|erase-and-check method
    erase-and-check method|DEFENDS_AGAINST|adversarial suffix attacks
    erase-and-check method|DEFENDS_AGAINST|insertion attacks
    erase-and-check method|DEFENDS_AGAINST|infusion attacks

  proposition: Hu et al. proposed Gradient Cuff to detect jailbreak prompts by exploring the refusal loss landscape.
    entity-attribute relationships:
    Gradient Cuff|PURPOSE|detect jailbreak prompts
    Gradient Cuff|TECHNIQUE|explore refusal loss landscape

  proposition: Xiong et al. proposed appending a defensive prompt patch to user queries to mitigate jailbreak effects.
    entity-attribute relationships:
    Xiong et al.|PROPOSED|defensive prompt patch technique
    defensive prompt patch|PURPOSE|mitigate jailbreak effects

topic: Jailbreak Evaluation Frameworks

  entities:
    HarmBench|Framework
    JailbreakEval|Toolkit
    JailbreakBench|Benchmark
    JAMBench|Benchmark
    Llama3 Guard|Model
    Sorry-Bench|Data Source

  proposition: Chu et al. evaluate jailbreak methods using 13 cutting-edge methods across four categories, 160 questions from 16 violation categories, and six popular Large Language Models.
    entity-attribute relationships:
    Chu et al.|CONDUCTED|jailbreak method evaluation
    evaluation|SCOPE|13 cutting-edge methods
    evaluation|INCLUDES|160 questions
    evaluation|COVERS|16 violation categories
    evaluation|INVOLVES|six Large Language Models

  proposition: HarmBench is a standardized evaluation framework for jailbreaking attacks, including 18 red teaming methods.
    entity-attribute relationships:
    HarmBench|TYPE|standardized evaluation framework
    HarmBench|INCLUDES|18 red teaming methods

  proposition: Benchmark Setting
    entity-attribute relationships:
    Sorry-Bench|TYPE|fine-grained taxonomy
    Sorry-Bench|CONTAINS|45 potentially unsafe topics
    Llama3 Guard|PURPOSE|evaluate jailbreak success
    Percentage of Refusing to Answer|TYPE|evaluation metric