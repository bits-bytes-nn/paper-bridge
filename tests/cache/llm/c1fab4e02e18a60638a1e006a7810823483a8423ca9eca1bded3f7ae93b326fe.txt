Performance Metrics for Large Language and Vision-Language Models

50 is a baseline or reference score
GPT-3.5-turbo has an average performance of 70.33
Claude-3.5-Sonnet has an average performance of 98.17
Claude-3-Haiku has an average performance of 92.00
Gemini-1.5-Pro has an average performance of 82.00
Gemini-1.5-Flash has an average performance of 74.67
Gemma-2-27B has an average performance of 95.00
Llama-3.1-70B has an average performance of 95.00
Llama-3.1-8B has an average performance of 90.00
Mixtral-8*22B has a perfect average score of 100.00
Mixtral-8*7B has a perfect average score of 100.00
GLM-4-Plus has a perfect average score of 100.00
Qwen-2.5-72B has a perfect average score of 100.00
Deepseek-chat has a perfect average score of 100.00
Yi-lightning has a perfect average score of 100.00
GPT-4o has a jailbreak results average of 97.20
GPT-4o-mini has a jailbreak results average of 96.30
Claude-3.5-Sonnet has an incomplete jailbreak results entry