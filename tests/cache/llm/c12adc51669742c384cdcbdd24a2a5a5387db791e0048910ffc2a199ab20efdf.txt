Research Papers on Language Model Augmentation and Knowledge Editing

Shunyu Yao and colleagues published "React: Synergizing reasoning and acting in language models" in 2022.
Tianyu Liu and colleagues created a token-level reference-free hallucination detection benchmark for free-form text generation in 2021.
Chengshu Li and colleagues proposed "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator" in 2023.
Baolin Peng and colleagues investigated improving large language models with external knowledge and automated feedback in 2023.
Luyu Gao and colleagues developed "RARR: Researching and Revising What Language Models Say, Using Language Models" in 2022.
Garima Agrawal and colleagues published a survey on whether knowledge graphs can reduce hallucinations in large language models in 2023.
Junyi Liu and colleagues introduced TCRA-LLM for token compression retrieval augmented large language model inference cost reduction in 2023.
Ori Yoran and colleagues explored answering questions by meta-reasoning over multiple chains of thought in 2023.
Gr√©goire Mialon and colleagues published a survey on augmented language models in 2023.
Yunzhi Yao and colleagues examined editing large language models: problems, methods, and opportunities in 2023.
Song Wang and colleagues conducted a survey on knowledge editing for large language models in 2023.
Nicola De Cao and colleagues studied editing factual knowledge in language models in 2021.
Eric Mitchell and colleagues investigated memory-based model editing at scale in 2022.
Anton Sinitsin and colleagues proposed editable neural networks in 2020.
Zeyu Huang and colleagues developed Transformer-Patcher: One mistake worth one neuron in 2023.
Kevin Meng and colleagues researched mass-editing memory in a transformer in 2022.
Jiaxin Qin and colleagues explored why new knowledge creates messy ripple effects in large language models.