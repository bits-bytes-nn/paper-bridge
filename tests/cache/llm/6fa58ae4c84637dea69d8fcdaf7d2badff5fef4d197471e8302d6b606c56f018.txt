Trustworthiness and Safety in Multi-Agent Systems and Medical Applications

Huang et al. explored multi-agent topology resilience against attacks.
Yu et al. studied topological safety in multi-agent networks.
Yu et al. identified critical phenomena called Agent Hallucination and Aggregation Safety.
Zhang et al. proposed Psysafe, a benchmark for evaluating safety of psychological-based attacks in multi-agent systems.
Agent-SafetyBench evaluated LLM-based agents across 349 interaction environments and 2,000 test cases.
Agent-SafetyBench found that none of the 16 tested agents surpass a 60% safety score.
SafeAgentBench focuses on safety-aware task planning for embodied LLM agents.
SafeAgentBench offers 750 tasks covering 10 hazards.
SafeAgentBench revealed that the leading baseline rejects only 5% of hazardous tasks.
Tian et al. probed agent safety through manual jailbreak prompts and a virtual evil plan development team.
Xu et al. utilized an LLM-based agent for automatic red-teaming to generate context-aware jailbreak prompts.
Dong et al. leveraged LLM agents to jailbreak text-to-image models.
AgentSmith and another work discussed malicious content propagation between generative model-based agents.
Zeng et al. used synthetic data to enhance privacy-preservation of LLMs in RAG scenarios.
TrustAgent enhanced LLM agent safety across multiple domains by identifying and mitigating potential dangers during planning.
Yoffe et al. proposed the DebUnc framework to mitigate hallucination in agents using uncertainty estimations.

Medical Applications of Generative Foundation Models

Generative foundation models in medical applications enable automation of complex diagnostic and decision-making tasks.
Medical agents powered by LLMs and VLMs support clinicians and patients in diagnostics, treatment planning, and patient monitoring.
Multi-modal medical agents combine text and image inputs to deliver accurate and context-aware diagnostic assistance.
Validating model performance in rare or edge-case scenarios remains a critical challenge.
Real-time monitoring systems are needed to continuously evaluate agent outputs against clinical safety standards.
Generative models in medical video generation offer opportunities for medical education, training, and diagnostics.
Generated medical videos can visualize procedures, disease progression, and anatomical changes.
Generated medical content must accurately reflect clinical realities to avoid misleading practitioners.
Anomaly detection and privacy-preserving model architectures are essential to mitigate risks.
Automated medical report generation can analyze medical images and patient data to draft detailed reports.
Validation pipelines cross-reference generated reports with ground-truth annotations.
Explainability features allow users to trace the reasoning behind generated conclusions.
Algorithmic bias in medical generative models can result from underrepresentation of certain demographics.
Addressing algorithmic bias requires building representative datasets and implementing continuous fairness evaluations.
Research efforts have proposed real-time monitoring systems for clinical safety.
Privacy-preserving architectures have been implemented to enhance data security during model training and deployment.