Research Papers on AI and Cybersecurity Risks

Teams of Large Language Model Agents can exploit zero-day vulnerabilities.
PentestAgent incorporates Large Language Model Agents to automated penetration testing.
AI Cyber Risk Benchmark explores automated exploitation capabilities.
ChatGPT, FraudGPT, and WormGPT pose threats in social engineering attacks.
Large Language Models can generate potential security risks in cyber domains.
Large Language Models can be used as tools for cyber attacks on vehicle systems.
Generative AI and Large Language Models are changing the landscape of online misinformation.
Artificial intelligence can generate fraudulent but authentic-looking scientific medical articles.
Large Language Models present potential risks for biological misuse.
Simulated misuse of Large Language Models exists in clinical credit systems.
Major technology companies have developed AI security risk assessment frameworks.
Researchers are surveying methods for detecting Large Language Model-generated text.
Language models can be used for detecting unknown attacks in network traffic.
Artificial intelligence technologies introduce complex security and ethical challenges across multiple domains.