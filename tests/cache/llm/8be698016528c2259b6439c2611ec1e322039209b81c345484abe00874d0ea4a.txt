Emotion in Large Language Models (LLMs)
Emotional intelligence is a foundational human attribute defined by competencies processing emotional information.
Emotional intelligence is increasingly recognized by scholars, governments, and industrial applications.
Lack of emotional competencies can result in severe consequences in moral decision and service-oriented applications.
Emotions refer to a model's ability to recognize and simulate emotional contexts in text.
Emotions influence an LLM's understanding of scenarios and response content.
LLMs do not actually experience emotions.
Studies have covered emotion detection, manipulation, and related areas.
LLMs face significant limitations in handling complex emotional mixtures.
LLMs struggle with manipulating their emotional outputs.
Challenges stem from LLMs' lack of nuanced understanding of emotional states.
Researchers use false-belief tasks to enable LLMs to infer unobservable mental states.
Evaluating an LLM's current emotional state requires methods similar to human Theory of Mind.
Recent approaches use specific prompts to enhance LLMs' sensitivity to emotional stimuli.
Some studies explore limb-level emotion manipulation to refine LLMs' emotional content handling.
Surveys have been conducted on LLMs' abilities to detect and generate emotional responses.

Culture in Large Language Models
Culture is a multifaceted concept encompassing identities like language, nationality, region, religion, and gender.
Understanding cultural awareness can help develop fairer and more applicable LLMs.
Culture in LLMs involves understanding and generating content related to different cultural contexts.
LLMs should handle cultural references with sensitivity and respect.
CulturePark is a multi-agent communication framework for cultural data collection.
CultureLLM is a cost-effective solution to incorporate cultural differences into LLMs.
CultureBank is a knowledge base of cultural descriptors from user self-narratives.
CulturalTeaming is an interactive red-teaming system for evaluating multicultural LLM knowledge.
LLMs can differentiate between cultural values but may not always uphold them.
Cultiverse enhances cross-cultural dialogue interpretation using LLMs.
Datasets like BLEnD and CRAFT address geographical and cultural biases in LLMs.