Research Papers on Embodied AI, Vision-Language Models, and Robotic Systems

Matterport3D is a research paper about learning from RGB-D data in indoor environments published at the International Conference on 3D Vision in 2017.
Yang Liu and colleagues published a comprehensive survey on Aligning Cyber Space with Physical World in Embodied AI in 2024.
Guanzhi Wang and collaborators developed Voyager, an open-ended embodied agent with large language models, published in Transactions on Machine Learning Research in 2024.
Yunfan Jiang and team introduced VIMA, a general robot manipulation system with multimodal prompts, at the Fortieth International Conference on Machine Learning in 2023.
Brianna Zitkovich and colleagues presented RT-2, a vision-language-action model that transfers web knowledge to robotic control, at the 7th Annual Conference on Robot Learning in 2023.
Xingcheng Zhou and researchers published a survey and outlook on vision language models in autonomous driving in IEEE Transactions on Intelligent Vehicles in 2024.
Tianrui Guan and team developed TNS, a terrain traversability mapping and navigation system for autonomous excavators, at Robotics: Science and Systems XVIII in 2021.
Tianrui Guan and colleagues expanded their work with TNES, a terrain traversability mapping, navigation, and excavation system for autonomous excavators, published in Autonomous Robots in 2023.
Silen Naihin and researchers explored testing language model agents safely in the wild, publishing a paper on ArXiv in 2023.
Grégoire Délétang and team conducted a causal analysis of agent behavior for AI safety, publishing on ArXiv in 2021.
Paul Knott and collaborators evaluated the robustness of collaborative agents at the International Conference on Autonomous Agents and MultiAgent Systems in 2021.
James F. Mullen and colleagues created a dataset for enabling embodied agents to detect anomalous situations, published in IEEE Robotics and Automation Letters in 2024.
Kaiming He and researchers developed deep residual learning for image recognition, presenting at the IEEE Conference on Computer Vision and Pattern Recognition in 2016.
Alex H Lang and team created PointPillars, a fast encoder for object detection from point clouds.