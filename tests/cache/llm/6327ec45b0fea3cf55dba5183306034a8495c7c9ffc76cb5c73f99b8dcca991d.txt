Research Papers on AI, Machine Learning, and Human-AI Interaction: A Bibliographic Overview

Riccardo Miotto et al. published a review on deep learning in healthcare in 2018.
David A Van Valen et al. developed deep learning for automated quantitative analysis of individual cells in live-cell imaging experiments in 2016.
Piotr S Gromski et al. explored chemical space using algorithms and automation in 2019.
Mayk Caldas Ramos et al. conducted a review of large language models and autonomous agents in chemistry in 2024.
Alexander Robey et al. studied jailbreaking of LLM-controlled robots in 2024.
Rumaisa Azeem et al. highlighted risks of LLM-driven robots enacting discrimination, violence, and unlawful actions in 2024.
Yueen Ma et al. published a survey on vision-language-action models for embodied AI in 2024.
Pranav Guruprasad et al. benchmarked vision, language, and action models on robotic learning tasks in 2024.
Pengtao Jiang et al. conducted a literature review on users' acceptance of artificial intelligence applications in 2024.
Gaole He et al. studied the illusion of human competence that can hinder appropriate reliance on AI systems in 2023.
Edona Elshan et al. examined design elements affecting user acceptance of intelligent agents from past to future in 2022.
Brendan Walker-Munro and Zena Assaad explored blameworthiness and liability in human-machine teaming in 2022.
Philippa Ryan et al. modeled responsibility for AI-based safety-critical systems in 2023.
Yahang Qi et al. investigated causal responsibility attribution for human-AI collaboration in 2024.
Tim Miller discussed explainable AI and hypothesis-driven decision support in 2023.
Jakob Mökander examined legal, ethical, and technical approaches to AI auditing in 2023.
Miroslaw Staron et al. explored testing, debugging, and log analysis with modern AI tools in 2024.
Paulius Rauba et al. proposed context-aware testing as a new paradigm for model testing with large language models in 2024.
U.S. Government Accountability Office published an accountability framework for AI in federal agencies in 2021.
Ángel Alexander Cabrera et al. developed methods for discovering and validating AI errors using crowdsourced failure reports in 2021.