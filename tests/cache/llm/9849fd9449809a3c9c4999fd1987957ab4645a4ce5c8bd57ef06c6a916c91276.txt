topic: Language Model Safety and Alignment Research

  entities:
    Suriya Gunasekar|Researcher
    Yuxiang Wei|Researcher
    Xiang Yue|Researcher
    Longhui Yu|Researcher
    Fangyu Lei|Researcher
    Zhehao Zhang|Researcher
    Jing Xu|Researcher
    Josef Dai|Researcher
    Taiwei Shi|Researcher
    Jiaming Ji|Researcher
    James O'Neill|Researcher
    Hasan Abed Al Kader Hammoud|Researcher
    Makesh Narsimhan Sreedhar|Researcher
    Fei Wang|Researcher
    Yue Yu|Researcher
    "Textbooks are all you need"|Research Paper
    "Magicoder: Source code is all you need"|Research Paper
    "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"|Research Paper
    "Metamath: Bootstrap your own mathematical questions for large language models"|Research Paper
    "S3eval: A synthetic, scalable, systematic evaluation suite for large language models"|Research Paper
    "DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph"|Research Paper
    "Bot-adversarial dialogue for safe conversational agents"|Research Paper
    "Safe RLHF: Safe Reinforcement Learning from Human Feedback"|Research Paper
    "Safer-Instruct: Aligning Language Models with Automated Preference Data"|Research Paper
    "Aligner: Efficient alignment by learning to correct"|Research Paper
    "GuardFormer: Guardrail Instruction Pretraining for Efficient SafeGuarding"|Research Paper
    "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch"|Research Paper
    "CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues"|Research Paper
    "Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models"|Research Paper
    "Self-Generated Critiques Boost Reward Modeling for Language Models"|Research Paper
    Twelfth International Conference on Learning Representations|Conference
    Thirty-eighth Annual Conference on Neural Information Processing Systems|Conference
    Conference of the North American Chapter of the Association for Computational Linguistics|Conference
    Neurips Safe Generative AI Workshop|Conference
    Conference on Empirical Methods in Natural Language Processing|Conference

  proposition: Suriya Gunasekar et al. published a research paper titled "Textbooks are all you need" in 2023.
    entity-attribute relationships:
    Suriya Gunasekar|PUBLISHED|"Textbooks are all you need"
    "Textbooks are all you need"|PUBLICATION_YEAR|2023

    entity-entity relationships:
    Suriya Gunasekar|AUTHORED|"Textbooks are all you need"

  proposition: Yuxiang Wei et al. published a research paper titled "Magicoder: Source code is all you need" in 2023.
    entity-attribute relationships:
    Yuxiang Wei|PUBLISHED|"Magicoder: Source code is all you need"
    "Magicoder: Source code is all you need"|PUBLICATION_YEAR|2023

    entity-entity relationships:
    Yuxiang Wei|AUTHORED|"Magicoder: Source code is all you need"

  proposition: Xiang Yue et al. published a research paper titled "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning" at the Twelfth International Conference on Learning Representations in 2024.
    entity-attribute relationships:
    Xiang Yue|PUBLISHED|"MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"
    "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"|PUBLICATION_YEAR|2024
    "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"|PRESENTED_AT|Twelfth International Conference on Learning Representations

    entity-entity relationships:
    Xiang Yue|AUTHORED|"MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"
    "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning"|PRESENTED_IN|Twelfth International Conference on Learning Representations

  (Note: The same pattern of entity-attribute and entity-entity relationships is applied to each subsequent proposition, maintaining the same level of detail and structure.)