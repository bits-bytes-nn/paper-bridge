topic: Hallucination Evaluation Methodology

  entities:
    Large Language Models|Model
    ROME|Method
    ITI|Method
    Llama|Model
    Retrieval-Augmented Generation|Approach
    Contrastive Decoding|Method
    Factual-Nucleus Sampling|Method
    Context-Aware Decoding|Method
    Wikipedia|Data Source
    Snopes|Data Source
    FactCheck.org|Data Source

  proposition: [647-653, 597, 654, 589, 655, 595, 596] retrieve information from external knowledge bases, structured databases, specific websites, search engine APIs, and various external tools.
    entity-attribute relationships:
    
    entity-entity relationships:
    External Knowledge Bases|CONTAINS|Structured Databases
    External Knowledge Bases|CONTAINS|Specific Websites
    External Knowledge Bases|CONTAINS|Search Engine APIs
    External Knowledge Bases|CONTAINS|External Tools

  proposition: Model editing allows for modification of Large Language Model (LLM) behavior in a data- and computation-efficient manner.
    entity-attribute relationships:
    Large Language Models|MODIFIABLE|Behavior
    
    entity-entity relationships:

  proposition: Model editing methods often involve incorporating an auxiliary sub-network or directly modifying original model parameters.
    entity-attribute relationships:
    Model Editing Methods|INVOLVES|Auxiliary Sub-Network
    Model Editing Methods|INVOLVES|Model Parameter Modification
    
    entity-entity relationships:

  proposition: Meng et al. propose ROME, a method that modifies feedforward weights to update specific factual associations in GPT.
    entity-attribute relationships:
    ROME|MODIFIES|Feedforward Weights
    
    entity-entity relationships:
    ROME|UPDATES|GPT

  proposition: Li et al. introduce inference-time intervention (ITI), a technique that identifies attention heads associated with truthfulness.
    entity-attribute relationships:
    ITI|IDENTIFIES|Attention Heads
    ITI|ASSOCIATED_WITH|Truthfulness
    
    entity-entity relationships:

  proposition: ITI shifts activations along truth-correlated directions to elicit truthful answers from Llama.
    entity-attribute relationships:
    ITI|SHIFTS|Activations
    
    entity-entity relationships:
    ITI|GENERATES|Truthful Answers
    ITI|APPLIED_TO|Llama

  proposition: Retrieval-Augmented Generation (RAG) adds controllability to LLMs' knowledge sources.
    entity-attribute relationships:
    Retrieval-Augmented Generation|ADDS|Controllability
    
    entity-entity relationships:
    Retrieval-Augmented Generation|APPLIED_TO|Large Language Models

  proposition: The evaluation examines LLMs' hallucination tendencies in two scenarios:
    entity-attribute relationships:
    Large Language Models|EXHIBITS|Hallucination Tendencies
    
    entity-entity relationships:

  proposition: Internal knowledge scenario uses existing QA datasets covering adversarial QA, commonsense QA, and human falsehood QA.
    entity-attribute relationships:
    Internal Knowledge Scenario|USES|QA Datasets
    
    entity-entity relationships:

  proposition: The evaluation employs the LLM-as-a-Judge paradigm to assess model output.
    entity-attribute relationships:
    
    entity-entity relationships:
    LLM|JUDGES|Model Output

  proposition: A web browsing agent retrieves question-answer and claim-label pairs.
    entity-attribute relationships:
    Web Browsing Agent|RETRIEVES|Question-Answer Pairs
    Web Browsing Agent|RETRIEVES|Claim-Label Pairs
    
    entity-entity relationships:

  proposition: QA task data is retrieved from reliable sources like Wikipedia.
    entity-attribute relationships:
    
    entity-entity relationships:
    QA Task Data|SOURCED_FROM|Wikipedia

  proposition: Fact-checking task data is gathered from websites like Snopes and FactCheck.org.
    entity-attribute relationships:
    
    entity-entity relationships:
    Fact-Checking Task Data|SOURCED_FROM|Snopes
    Fact-Checking Task Data|SOURCED_FROM|FactCheck.org

topic: Decoding Strategies

  entities:
    Contrastive Decoding|Method
    Factual-Nucleus Sampling|Method
    Context-Aware Decoding|Method

  proposition: Decoding strategies determine how the next token is selected from the probability distribution generated by LLMs.
    entity-attribute relationships:
    Decoding Strategies|DETERMINES|Token Selection
    
    entity-entity relationships:

  proposition: Li et al. propose contrastive decoding, leveraging differences between expert and amateur models.
    entity-attribute relationships:
    Contrastive Decoding|LEVERAGES|Model Differences
    
    entity-entity relationships:

  proposition: Lee et al. conduct factuality assessments of LLM-generated content using various decoding strategies.
    entity-attribute relationships:
    
    entity-entity relationships:
    Lee et al.|ASSESSES|LLM-Generated Content

  proposition: Lee et al. introduce factual-nucleus sampling decoding algorithm.
    entity-attribute relationships:
    
    entity-entity relationships:
    Lee et al.|INTRODUCES|Factual-Nucleus Sampling

  proposition: Shi et al. propose a context-aware decoding strategy to encourage LLMs to pay closer attention to context during generation.
    entity-attribute relationships:
    Context-Aware Decoding|ENCOURAGES|Context Attention
    
    entity-entity relationships:
    Context-Aware Decoding|APPLIED_TO|Large Language Models

  proposition: The context-aware strategy aims to override prior knowledge with reliable information to reduce hallucinations.
    entity-attribute relationships:
    Context-Aware Decoding|AIMS|Hallucination Reduction
    
    entity-entity relationships: