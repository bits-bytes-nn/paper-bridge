topic: Hallucination in Vision-Language Models

  entities:
    Hallucination|Social Concept
    Vision-Language Models|Technological Concept
    HallusionBench|Benchmark
    Bingo|Benchmark
    AutoHallusion|Tool
    VHTest|Tool
    CHAIR|Metric
    POPE|Metric
    GPT-4o|Model
    Claude-3.5-Sonnet|Model
    LRV-Instruction|Method

  proposition: Hallucination in VLMs refers to generating content that is factually inconsistent with visual context or common sense.
    entity-attribute relationships:
    Hallucination|DESCRIBED_BY|factually inconsistent with visual context
    Hallucination|DESCRIBED_BY|inconsistent with common sense
    
    entity-entity relationships:
    Hallucination|OCCURS_IN|Vision-Language Models

  proposition: Hallucination can occur in tasks like image captioning, visual question answering, and visual-language navigation.
    entity-attribute relationships:
    Hallucination|OCCURS_IN|image captioning
    Hallucination|OCCURS_IN|visual question answering
    Hallucination|OCCURS_IN|visual-language navigation

  proposition: HallusionBench evaluates VLMs' ability to handle complex image-context reasoning.
    entity-attribute relationships:
    HallusionBench|EVALUATES|VLMs' image-context reasoning ability

  proposition: HallusionBench focuses on two failure modes: language hallucination and visual illusion.
    entity-attribute relationships:
    HallusionBench|FOCUSES_ON|language hallucination
    HallusionBench|FOCUSES_ON|visual illusion

  proposition: Object hallucination involves generating nonexistent objects.
    entity-attribute relationships:
    Hallucination|TYPE|object hallucination
    Hallucination|INVOLVES|generating nonexistent objects

  proposition: Metrics like CHAIR and POPE assess caption relevance and hallucination levels.
    entity-entity relationships:
    CHAIR|ASSESSES|caption relevance
    POPE|ASSESSES|hallucination levels

  proposition: GPT-4o has the highest overall accuracy of 60.70% on HallusionBench.
    entity-attribute relationships:
    GPT-4o|ACCURACY|60.70%
    GPT-4o|PERFORMANCE_ON|HallusionBench

  proposition: Claude-3.5-Sonnet achieves 62.19% overall accuracy.
    entity-attribute relationships:
    Claude-3.5-Sonnet|ACCURACY|62.19%