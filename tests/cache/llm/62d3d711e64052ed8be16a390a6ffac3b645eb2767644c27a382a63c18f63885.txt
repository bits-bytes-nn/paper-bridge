Research Papers on AI Safety, Ethics, and Emerging Risks

Position paper proposes an adaptive interpretation of helpful, honest, and harmless AI principles.
OpenAI provides a moderation quickstart guide for AI systems.
Research paper explores a strong reject mechanism for preventing AI jailbreaks.
OpenAI researchers investigate improving model safety behavior using rule-based rewards.
Research paper examines societal impact of open foundation models.
Academic work focuses on developing trustworthy large language models.
Research paper discusses frontier AI regulation and managing emerging risks to public safety.
Studies explore defense mechanisms against attribute inference attacks in machine learning.
Research investigates bad data injection attacks and defense strategies in smart grid systems.
Paper addresses ethical considerations in generative AI.
Research explores user-centric interactive AI for distributed diffusion models.
Study proposes a new sampling method in graphical recommendation systems.
Research examines machine learning models of cultural change.
Academic work uses natural language processing to identify residency application values.
Research investigates potential risks in user blocking mechanisms on social platforms.
Paper explores large language models for security operations center (SOC) security.
Research applies generative agents to epidemic modeling.
Study develops a social network simulation system using large language model-empowered agents.