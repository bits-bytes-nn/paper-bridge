Challenges and Applications of Text-to-Image Models

Text-to-image models have been widely applied in art and design, healthcare, and fashion domains.
Text-to-image models are susceptible to jailbreak attacks through adversarial prompts.
Jailbreak attacks can lead to unexpected or undesirable image outputs.
Text-to-image models may inadvertently leak sensitive information from training data.
Models might memorize and reproduce elements from the training set.
Memorization of training data can lead to privacy issues.
Text-to-image models may produce biased content due to biases in training data.
Models exhibit sensitivity to small perturbations in input prompts.
Small input prompt variations can cause substantial changes in generated images.
Recent research focuses on developing attack and defense mechanisms for text-to-image models.

Truthfulness in Text-to-Image Models

Truthfulness in text-to-image models refers to generating images precisely according to user queries.
Truthfulness includes following user requirements and generating images faithfully.
Traditional truthfulness evaluation uses metric-based methods like FID, SSIM, and LPIPS.
Traditional truthfulness evaluation also uses model-based methods like Inception Score and CLIP-score.
Existing metrics lack accurate measurement of truthfulness.
Lightweight model-based methods struggle with complex compositional text prompts.
Challenges include handling multiple objects, attribute bindings, spatial relations, and logical reasoning.
Recent research focuses on decomposing textual conditions using large language models.
Researchers are developing visual question-answer approaches to evaluate image truthfulness.
Advanced methods leverage visual language models to calculate condition-generation alignment scores.

Truthfulness Evaluation Methodology

GenVerse is used to generate a dataset of image captions for benchmarking truthfulness.
GenVerse maintains vocabularies of entities, attributes, and relations.
Elements are sampled based on real-world frequency distributions.
Sampled elements are arranged into keyword sequences using templates.
Templates are rephrased into natural language sentences by a large language model.
Two key checks ensure diversity: Similarity Checking and Group Checking.
The evaluation uses a Visual Question Answering (VQA) based approach.
TIFA is leveraged for atomic and interpretable evaluation.
Truthfulness is calculated by counting 'yes' and 'no' answers.
The methodology ensures caption diversity across real-world element distributions.